{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\r\n",
        "\r\n",
        "# Motivation"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\r\n",
        "\r\n",
        "import azureml.core\r\n",
        "from azureml.core import Workspace\r\n",
        "\r\n",
        "from azureml.core import Dataset\r\n",
        "from azureml.data.datapath import DataPath\r\n",
        "\r\n",
        "import os"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677360489861
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to Workspace"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "# Load the workspace from the saved config file\r\n",
        "ws = Workspace.from_config()\r\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ready to use Azure ML 1.48.0 to work with testerinos\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1677360492015
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "\r\n",
        "default_ds = ws.get_default_datastore()\r\n",
        "\r\n",
        "if 'titanic dataset' not in ws.datasets:\r\n",
        "    Dataset.File.upload_directory(src_dir='data',\r\n",
        "                              target=DataPath(default_ds, 'titanic-data/')\r\n",
        "                              )\r\n",
        "\r\n",
        "    #Create a tabular dataset from the path on the datastore (this may take a short while)\r\n",
        "    tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'titanic-data/titanic.csv'))\r\n",
        "\r\n",
        "    # Register the tabular dataset\r\n",
        "    try:\r\n",
        "        tab_data_set = tab_data_set.register(workspace=ws, \r\n",
        "                                name='titanic dataset',\r\n",
        "                                description='titanic data',\r\n",
        "                                tags = {'format':'CSV'},\r\n",
        "                                create_new_version=True)\r\n",
        "        print('Dataset registered.')\r\n",
        "    except Exception as ex:\r\n",
        "        print(ex)\r\n",
        "else:\r\n",
        "    print('Dataset already registered.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Validating arguments.\nArguments validated.\nUploading file to titanic-data/\nUploading an estimated of 3 files\nUploading data/.amlignore\nUploaded data/.amlignore, 1 files out of an estimated total of 3\nUploading data/.amlignore.amltmp\nUploaded data/.amlignore.amltmp, 2 files out of an estimated total of 3\nUploading data/titanic.csv\nUploaded data/titanic.csv, 3 files out of an estimated total of 3\nUploaded 3 files\nCreating new dataset\nDataset registered.\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677360503970
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "# Create a folder for the pipeline step files\r\n",
        "experiment_folder = 'titanic_pipeline'\r\n",
        "os.makedirs(experiment_folder, exist_ok=True)\r\n",
        "\r\n",
        "print(experiment_folder)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "titanic_pipeline\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677360504154
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/prep_titanic.py\r\n",
        "# Import libraries\r\n",
        "import os\r\n",
        "import argparse\r\n",
        "import pandas as pd\r\n",
        "import joblib\r\n",
        "from azureml.core import Run\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "from azureml.core import Workspace, Dataset, Datastore\r\n",
        "\r\n",
        "# Get parameters\r\n",
        "parser = argparse.ArgumentParser()\r\n",
        "parser.add_argument(\"--input-data\", type=str, dest='raw_dataset_id', help='raw dataset')\r\n",
        "parser.add_argument('--prepped-data', type=str, dest='prepped_data', default='prepped_data', help='Folder for results')\r\n",
        "args = parser.parse_args()\r\n",
        "save_folder = args.prepped_data\r\n",
        "\r\n",
        "\r\n",
        "subscription_id = '71fa0172-ce90-403c-94a9-14ce1e88f56a'\r\n",
        "resource_group = 'rg_eastus_44930_1_1677358905717'\r\n",
        "workspace_name = 'testerinos'\r\n",
        "\r\n",
        "# when this line executes, Azure will ask to authenticate... just need a better way to do it automatically as opposed to checking the userlogs\r\n",
        "ws= Workspace(subscription_id, resource_group, workspace_name)\r\n",
        "\r\n",
        "# Get the experiment run context\r\n",
        "run = Run.get_context()\r\n",
        "\r\n",
        "# load the data (passed as an input dataset)\r\n",
        "print(\"Loading Data...\")\r\n",
        "df = run.input_datasets['raw_data'].to_pandas_dataframe()\r\n",
        "\r\n",
        "# Log raw row count\r\n",
        "row_count = (len(df))\r\n",
        "run.log('raw_rows', row_count)\r\n",
        "\r\n",
        "# remove nulls\r\n",
        "df = df.dropna()\r\n",
        "\r\n",
        "# Normalize the numeric columns\r\n",
        "# Scaling isn't necessary for decision trees\r\n",
        "scaler = MinMaxScaler()\r\n",
        "num_cols = ['Age','Fare']\r\n",
        "#df[num_cols] = scaler.fit_transform(df[num_cols])\r\n",
        "\r\n",
        "df['Sex'] = df['Sex'].replace({'male':1,'female':0})\r\n",
        "\r\n",
        "# Log processed rows\r\n",
        "row_count = (len(df))\r\n",
        "run.log('processed_rows', row_count)\r\n",
        "\r\n",
        "# Save the prepped data\r\n",
        "print(\"Saving Data...\")\r\n",
        "os.makedirs(save_folder, exist_ok=True)\r\n",
        "save_path = os.path.join(save_folder,'data.csv')\r\n",
        "df.to_csv(save_path, index=False, header=True)\r\n",
        "\r\n",
        "# Saving Scalar File\r\n",
        "os.makedirs('outputs', exist_ok=True)\r\n",
        "scaler_file = os.path.join('outputs', 'titanic_scaler.pkl')\r\n",
        "joblib.dump(value=scaler, filename=scaler_file)\r\n",
        "\r\n",
        "\r\n",
        "default_ds = ws.get_default_datastore()\r\n",
        "Dataset.File.upload_directory(src_dir='outputs',\r\n",
        "                              target=DataPath(default_ds, 'titanic-data/')\r\n",
        "                              )\r\n",
        "\r\n",
        "# End the run\r\n",
        "run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting titanic_pipeline/prep_titanic.py\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/train_titanic.py\r\n",
        "# Import libraries\r\n",
        "from azureml.core import Run, Model\r\n",
        "import argparse\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import joblib\r\n",
        "import os\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.metrics import roc_auc_score\r\n",
        "from sklearn.metrics import roc_curve\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "# Get parameters\r\n",
        "parser = argparse.ArgumentParser()\r\n",
        "parser.add_argument(\"--training-data\", type=str, dest='training_data', help='training data')\r\n",
        "args = parser.parse_args()\r\n",
        "training_data = args.training_data\r\n",
        "\r\n",
        "# Get the experiment run context\r\n",
        "run = Run.get_context()\r\n",
        "\r\n",
        "# load the prepared data file in the training folder\r\n",
        "print(\"Loading Data...\")\r\n",
        "file_path = os.path.join(training_data,'data.csv')\r\n",
        "titanic = pd.read_csv(file_path)\r\n",
        "\r\n",
        "# Separate features and labels\r\n",
        "X, y = titanic[['Age','Sex','Fare']].values, titanic['Survived'].values\r\n",
        "\r\n",
        "# Split data into training set and test set\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\r\n",
        "\r\n",
        "# Train adecision tree model\r\n",
        "print('Training a decision tree model...')\r\n",
        "model = LogisticRegression(random_state = 42).fit(X_train, y_train)\r\n",
        "\r\n",
        "# calculate accuracy\r\n",
        "y_hat = model.predict(X_test)\r\n",
        "acc = np.average(y_hat == y_test)\r\n",
        "print('Accuracy:', acc)\r\n",
        "run.log('Accuracy', np.float(acc))\r\n",
        "\r\n",
        "# calculate AUC\r\n",
        "y_scores = model.predict_proba(X_test)\r\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\r\n",
        "print('AUC: ' + str(auc))\r\n",
        "run.log('AUC', np.float(auc))\r\n",
        "\r\n",
        "# plot ROC curve\r\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\r\n",
        "fig = plt.figure(figsize=(6, 4))\r\n",
        "# Plot the diagonal 50% line\r\n",
        "plt.plot([0, 1], [0, 1], 'k--')\r\n",
        "# Plot the FPR and TPR achieved by our model\r\n",
        "plt.plot(fpr, tpr)\r\n",
        "plt.xlabel('False Positive Rate')\r\n",
        "plt.ylabel('True Positive Rate')\r\n",
        "plt.title('ROC Curve')\r\n",
        "run.log_image(name = \"ROC\", plot = fig)\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# Save the trained model in the outputs folder\r\n",
        "print(\"Saving model...\")\r\n",
        "os.makedirs('outputs', exist_ok=True)\r\n",
        "model_file = os.path.join('outputs', 'titanic_model.pkl')\r\n",
        "joblib.dump(value=model, filename=model_file)\r\n",
        "\r\n",
        "\r\n",
        "# Register the model\r\n",
        "print('Registering model...')\r\n",
        "Model.register(workspace=run.experiment.workspace,\r\n",
        "               model_path = model_file,\r\n",
        "               model_name = 'titanic_model',\r\n",
        "               tags={'Training context':'Pipeline'},\r\n",
        "               properties={'AUC': np.float(auc), 'Accuracy': np.float(acc)})\r\n",
        "\r\n",
        "\r\n",
        "run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting titanic_pipeline/train_titanic.py\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "\r\n",
        "cluster_name = \"sweetdreams\"\r\n",
        "\r\n",
        "try:\r\n",
        "    # Check for existing compute target\r\n",
        "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\r\n",
        "    print('Found existing cluster, use it.')\r\n",
        "except ComputeTargetException:\r\n",
        "    # If it doesn't already exist, create it\r\n",
        "    try:\r\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\r\n",
        "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\r\n",
        "        pipeline_cluster.wait_for_completion(show_output=True)\r\n",
        "    except Exception as ex:\r\n",
        "        print(ex)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing cluster, use it.\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677360504906
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/experiment_env.yml\r\n",
        "name: experiment_env\r\n",
        "dependencies:\r\n",
        "- python=3.6.2\r\n",
        "- scikit-learn\r\n",
        "- ipykernel\r\n",
        "- matplotlib\r\n",
        "- pandas\r\n",
        "- pip\r\n",
        "- pip:\r\n",
        "  - azureml-defaults\r\n",
        "  - pyarrow"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting titanic_pipeline/experiment_env.yml\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\r\n",
        "from azureml.core.runconfig import RunConfiguration\r\n",
        "\r\n",
        "# Create a Python environment for the experiment (from a .yml file)\r\n",
        "experiment_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/experiment_env.yml\")\r\n",
        "\r\n",
        "# Register the environment \r\n",
        "experiment_env.register(workspace=ws)\r\n",
        "registered_env = Environment.get(ws, 'experiment_env')\r\n",
        "\r\n",
        "# Create a new runconfig object for the pipeline\r\n",
        "pipeline_run_config = RunConfiguration()\r\n",
        "\r\n",
        "# Use the compute you created above. \r\n",
        "pipeline_run_config.target = pipeline_cluster\r\n",
        "\r\n",
        "# Assign the environment to the run configuration\r\n",
        "pipeline_run_config.environment = registered_env\r\n",
        "\r\n",
        "print (\"Run configuration created.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Run configuration created.\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677360505313
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data import OutputFileDatasetConfig\r\n",
        "from azureml.pipeline.steps import PythonScriptStep\r\n",
        "\r\n",
        "\r\n",
        "# Get the training dataset\r\n",
        "titanic_ds = ws.datasets.get(\"titanic dataset\")\r\n",
        "\r\n",
        "# Create an OutputFileDatasetConfig (temporary Data Reference) for data passed from step 1 to step 2\r\n",
        "prepped_data = OutputFileDatasetConfig(\"prepped_data\")\r\n",
        "\r\n",
        "# Step 1, Run the data prep script\r\n",
        "prep_step = PythonScriptStep(name = \"Prepare Data\",\r\n",
        "                                source_directory = experiment_folder,\r\n",
        "                                script_name = \"prep_titanic.py\",\r\n",
        "                                arguments = ['--input-data', titanic_ds.as_named_input('raw_data'),\r\n",
        "                                             '--prepped-data', prepped_data],\r\n",
        "                                compute_target = pipeline_cluster,\r\n",
        "                                runconfig = pipeline_run_config,\r\n",
        "                                allow_reuse = True)\r\n",
        "\r\n",
        "# Step 2, run the training script\r\n",
        "train_step = PythonScriptStep(name = \"Train and Register Model\",\r\n",
        "                                source_directory = experiment_folder,\r\n",
        "                                script_name = \"train_titanic.py\",\r\n",
        "                                arguments = ['--training-data', prepped_data.as_input()],\r\n",
        "                                compute_target = pipeline_cluster,\r\n",
        "                                runconfig = pipeline_run_config,\r\n",
        "                                allow_reuse = True)\r\n",
        "\r\n",
        "print(\"Pipeline steps defined\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Pipeline steps defined\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677360505752
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "from azureml.core import Experiment\r\n",
        "from azureml.pipeline.core import Pipeline\r\n",
        "from azureml.widgets import RunDetails\r\n",
        "\r\n",
        "# Construct the pipeline\r\n",
        "pipeline_steps = [prep_step, train_step]\r\n",
        "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\r\n",
        "print(\"Pipeline is built.\")\r\n",
        "\r\n",
        "# Create an experiment and run the pipeline\r\n",
        "experiment = Experiment(workspace=ws, name = 'titanic-pipeline')\r\n",
        "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\r\n",
        "print(\"Pipeline submitted for execution.\")\r\n",
        "RunDetails(pipeline_run).show()\r\n",
        "pipeline_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Pipeline is built.\nCreated step Prepare Data [60ef3f3c][c63f3356-953f-42e7-a381-ff605c8876f4], (This step will run and generate new outputs)\nCreated step Train and Register Model [af5f8645][8cf96612-cd6c-4e71-9e5c-fcf1d0def609], (This step will run and generate new outputs)\nSubmitted PipelineRun e772390f-c3db-4b31-a1ee-181dd16cd33e\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/e772390f-c3db-4b31-a1ee-181dd16cd33e?wsid=/subscriptions/71fa0172-ce90-403c-94a9-14ce1e88f56a/resourcegroups/rg_eastus_44930_1_1677358905717/workspaces/testerinos&tid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3\nPipeline submitted for execution.\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', â€¦",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "998d710b009a46d089a7a6669b259f7c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Running\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/e772390f-c3db-4b31-a1ee-181dd16cd33e?wsid=/subscriptions/71fa0172-ce90-403c-94a9-14ce1e88f56a/resourcegroups/rg_eastus_44930_1_1677358905717/workspaces/testerinos&tid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3\", \"run_id\": \"e772390f-c3db-4b31-a1ee-181dd16cd33e\", \"run_properties\": {\"run_id\": \"e772390f-c3db-4b31-a1ee-181dd16cd33e\", \"created_utc\": \"2023-02-25T21:28:30.041025Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\", \"azureml.continue_on_step_failure\": \"False\", \"azureml.continue_on_failed_optional_input\": \"True\", \"azureml.pipelineComponent\": \"pipelinerun\"}, \"tags\": {}, \"end_time_utc\": null, \"status\": \"Running\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://testerinos7033210533.blob.core.windows.net/azureml/ExperimentRun/dcid.e772390f-c3db-4b31-a1ee-181dd16cd33e/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=eq0xu%2FRjisioJOhggmAr%2FiL4OA6PkC6U7lNcLduxb3s%3D&skoid=cebaf477-d627-4990-b5f8-fabf0abe5be8&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-25T21%3A18%3A32Z&ske=2023-02-27T05%3A28%3A32Z&sks=b&skv=2019-07-07&st=2023-02-25T21%3A40%3A40Z&se=2023-02-26T05%3A50%3A40Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://testerinos7033210533.blob.core.windows.net/azureml/ExperimentRun/dcid.e772390f-c3db-4b31-a1ee-181dd16cd33e/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=PJASQOgufdwTUOQqMoCawFZ4TxvmV5Nbaznn18o4I3s%3D&skoid=cebaf477-d627-4990-b5f8-fabf0abe5be8&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-25T21%3A18%3A32Z&ske=2023-02-27T05%3A28%3A32Z&sks=b&skv=2019-07-07&st=2023-02-25T21%3A40%3A40Z&se=2023-02-26T05%3A50%3A40Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://testerinos7033210533.blob.core.windows.net/azureml/ExperimentRun/dcid.e772390f-c3db-4b31-a1ee-181dd16cd33e/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=7h23I9jWoq5K%2FpFmKGoAQTeORKspe%2BGhsYZvWpVlpOI%3D&skoid=cebaf477-d627-4990-b5f8-fabf0abe5be8&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-25T21%3A18%3A32Z&ske=2023-02-27T05%3A28%3A32Z&sks=b&skv=2019-07-07&st=2023-02-25T21%3A40%3A40Z&se=2023-02-26T05%3A50%3A40Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:26:21\", \"run_number\": \"1677360510\", \"run_queued_details\": {\"status\": \"Running\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"26c3eb41-ba15-49c9-ab2a-a8e544a633d4\", \"name\": \"Prepare Data\", \"status\": \"Running\", \"start_time\": \"2023-02-25T21:41:20.553568Z\", \"created_time\": \"2023-02-25T21:28:33.366634Z\", \"end_time\": \"\", \"duration\": \"0:26:18\", \"run_number\": 1677360513, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2023-02-25T21:28:33.366634Z\", \"is_reused\": \"\"}, {\"run_id\": \"\", \"name\": \"Train and Register Model\", \"status\": \"NotStarted\", \"start_time\": \"\", \"created_time\": \"\", \"end_time\": \"\", \"duration\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2023-02-25 21:28:31Z] Submitting 1 runs, first five are: 60ef3f3c:26c3eb41-ba15-49c9-ab2a-a8e544a633d4\\n\", \"graph\": {\"datasource_nodes\": {\"fadd2f65\": {\"node_id\": \"fadd2f65\", \"name\": \"titanic dataset\"}}, \"module_nodes\": {\"60ef3f3c\": {\"node_id\": \"60ef3f3c\", \"name\": \"Prepare Data\", \"status\": \"Running\", \"_is_reused\": false, \"run_id\": \"26c3eb41-ba15-49c9-ab2a-a8e544a633d4\"}, \"af5f8645\": {\"node_id\": \"af5f8645\", \"name\": \"Train and Register Model\", \"status\": \"NotStarted\"}}, \"edges\": [{\"source_node_id\": \"fadd2f65\", \"source_node_name\": \"titanic dataset\", \"source_name\": \"data\", \"target_name\": \"raw_data\", \"dst_node_id\": \"60ef3f3c\", \"dst_node_name\": \"Prepare Data\"}, {\"source_node_id\": \"60ef3f3c\", \"source_node_name\": \"Prepare Data\", \"source_name\": \"prepped_data\", \"target_name\": \"input_32e9c2aa\", \"dst_node_id\": \"af5f8645\", \"dst_node_name\": \"Train and Register Model\"}], \"child_runs\": [{\"run_id\": \"26c3eb41-ba15-49c9-ab2a-a8e544a633d4\", \"name\": \"Prepare Data\", \"status\": \"Running\", \"start_time\": \"2023-02-25T21:41:20.553568Z\", \"created_time\": \"2023-02-25T21:28:33.366634Z\", \"end_time\": \"\", \"duration\": \"0:26:18\", \"run_number\": 1677360513, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2023-02-25T21:28:33.366634Z\", \"is_reused\": \"\"}, {\"run_id\": \"\", \"name\": \"Train and Register Model\", \"status\": \"NotStarted\", \"start_time\": \"\", \"created_time\": \"\", \"end_time\": \"\", \"duration\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.48.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "PipelineRunId: e772390f-c3db-4b31-a1ee-181dd16cd33e\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/e772390f-c3db-4b31-a1ee-181dd16cd33e?wsid=/subscriptions/71fa0172-ce90-403c-94a9-14ce1e88f56a/resourcegroups/rg_eastus_44930_1_1677358905717/workspaces/testerinos&tid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3\nPipelineRun Status: Running\n\n\nStepRunId: 26c3eb41-ba15-49c9-ab2a-a8e544a633d4\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/26c3eb41-ba15-49c9-ab2a-a8e544a633d4?wsid=/subscriptions/71fa0172-ce90-403c-94a9-14ce1e88f56a/resourcegroups/rg_eastus_44930_1_1677358905717/workspaces/testerinos&tid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3\nStepRun( Prepare Data ) Status: Running\n\nStreaming azureml-logs/20_image_build_log.txt\n=============================================\n2023/02/25 21:28:50 Downloading source code...\n2023/02/25 21:28:51 Finished downloading source code\n2023/02/25 21:28:51 Creating Docker network: acb_default_network, driver: 'bridge'\n2023/02/25 21:28:52 Successfully set up Docker network: acb_default_network\n2023/02/25 21:28:52 Setting up Docker configuration...\n2023/02/25 21:28:52 Successfully set up Docker configuration\n2023/02/25 21:28:52 Logging in to registry: 6acc10c0eb1c448092f9d5e10581d6fe.azurecr.io\n2023/02/25 21:28:53 Successfully logged into 6acc10c0eb1c448092f9d5e10581d6fe.azurecr.io\n2023/02/25 21:28:53 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n2023/02/25 21:28:53 Scanning for dependencies...\n2023/02/25 21:28:53 Successfully scanned dependencies\n2023/02/25 21:28:53 Launching container with name: acb_step_0\nSending build context to Docker daemon  71.68kB\n\nStep 1/21 : FROM mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221101.v1@sha256:4505a963b2d34a42b5eaef48b8142ca98123d05d3a95eee3fe57551570a70e3b\nmcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221101.v1@sha256:4505a963b2d34a42b5eaef48b8142ca98123d05d3a95eee3fe57551570a70e3b: Pulling from azureml/openmpi4.1.0-ubuntu20.04\nd7bfe07ed847: Pulling fs layer\nd1327a17a430: Pulling fs layer\n69a9739a8058: Pulling fs layer\n1551e9d33102: Pulling fs layer\n726392826fd2: Pulling fs layer\n6ed0c5c30145: Pulling fs layer\nea261e5684f6: Pulling fs layer\n21207d3ea9d3: Pulling fs layer\nc9a742e394f6: Pulling fs layer\nb0c9de384791: Pulling fs layer\n1551e9d33102: Waiting\n726392826fd2: Waiting\n6ed0c5c30145: Waiting\nea261e5684f6: Waiting\n21207d3ea9d3: Waiting\nc9a742e394f6: Waiting\nb0c9de384791: Waiting\nd7bfe07ed847: Verifying Checksum\nd7bfe07ed847: Download complete\n69a9739a8058: Verifying Checksum\n69a9739a8058: Download complete\n726392826fd2: Verifying Checksum\n726392826fd2: Download complete\n1551e9d33102: Verifying Checksum\n1551e9d33102: Download complete\nea261e5684f6: Verifying Checksum\nea261e5684f6: Download complete\n6ed0c5c30145: Verifying Checksum\n6ed0c5c30145: Download complete\n21207d3ea9d3: Verifying Checksum\n21207d3ea9d3: Download complete\nb0c9de384791: Verifying Checksum\nb0c9de384791: Download complete\nd1327a17a430: Verifying Checksum\nd1327a17a430: Download complete\nc9a742e394f6: Verifying Checksum\nc9a742e394f6: Download complete\nd7bfe07ed847: Pull complete\nd1327a17a430: Pull complete\n69a9739a8058: Pull complete\n1551e9d33102: Pull complete\n726392826fd2: Pull complete\n6ed0c5c30145: Pull complete\nea261e5684f6: Pull complete\n21207d3ea9d3: Pull complete\nc9a742e394f6: Pull complete\nb0c9de384791: Pull complete\nDigest: sha256:4505a963b2d34a42b5eaef48b8142ca98123d05d3a95eee3fe57551570a70e3b\nStatus: Downloaded newer image for mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221101.v1@sha256:4505a963b2d34a42b5eaef48b8142ca98123d05d3a95eee3fe57551570a70e3b\n ---> b6fd6a8d28e9\nStep 2/21 : USER root\n ---> Running in 840ae7372797\nRemoving intermediate container 840ae7372797\n ---> 0ebf891db38a\nStep 3/21 : RUN mkdir -p $HOME/.cache\n ---> Running in 3c11b10f25bd\nRemoving intermediate container 3c11b10f25bd\n ---> 043bf9c2bfbe\nStep 4/21 : WORKDIR /\n ---> Running in 53393184fd8f\nRemoving intermediate container 53393184fd8f\n ---> a644ac891bf6\nStep 5/21 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n ---> 685ce178457b\nStep 6/21 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n ---> Running in 3b241bd4e362\nRemoving intermediate container 3b241bd4e362\n ---> 2d81814f9127\nStep 7/21 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n ---> 409c2cca92ee\nStep 8/21 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n ---> Running in 4c1b4e83d23f\nCollecting package metadata (repodata.json): ...working... done\nSolving environment: ...working... done\n\nDownloading and Extracting Packages\n\npyparsing-3.0.4      | 81 KB     |            |   0% \npyparsing-3.0.4      | 81 KB     | ########## | 100% \n\nbackcall-0.2.0       | 13 KB     |            |   0% \nbackcall-0.2.0       | 13 KB     | ########## | 100% \n\nkiwisolver-1.3.1     | 86 KB     |            |   0% \nkiwisolver-1.3.1     | 86 KB     | ########## | 100% \n\nfreetype-2.12.1      | 626 KB    |            |   0% \nfreetype-2.12.1      | 626 KB    | ########## | 100% \n\nentrypoints-0.3      | 12 KB     |            |   0% \nentrypoints-0.3      | 12 KB     | ########## | 100% \n\nzeromq-4.3.4         | 331 KB    |            |   0% \nzeromq-4.3.4         | 331 KB    | ########## | 100% \n\nlerc-3.0             | 196 KB    |            |   0% \nlerc-3.0             | 196 KB    | ########## | 100% \n\nmkl-2020.2           | 138.3 MB  |            |   0% \nmkl-2020.2           | 138.3 MB  | 8          |   8% \nmkl-2020.2           | 138.3 MB  | #9         |  20% \nmkl-2020.2           | 138.3 MB  | ###1       |  32% \nmkl-2020.2           | 138.3 MB  | ####3      |  43% \nmkl-2020.2           | 138.3 MB  | #####4     |  55% \nmkl-2020.2           | 138.3 MB  | ######5    |  66% \nmkl-2020.2           | 138.3 MB  | #######6   |  77% \nmkl-2020.2           | 138.3 MB  | ########7  |  88% \nmkl-2020.2           | 138.3 MB  | #########8 |  99% \nmkl-2020.2           | 138.3 MB  | ########## | 100% \n\nlibdeflate-1.8       | 51 KB     |            |   0% \nlibdeflate-1.8       | 51 KB     | ########## | 100% \n\nopenssl-1.0.2u       | 2.2 MB    |            |   0% \nopenssl-1.0.2u       | 2.2 MB    | ########## | 100% \n\nlibuuid-1.41.5       | 27 KB     |            |   0% \nlibuuid-1.41.5       | 27 KB     | ########## | 100% \n\npygments-2.11.2      | 759 KB    |            |   0% \npygments-2.11.2      | 759 KB    | ########## | 100% \n\nlibtiff-4.5.0        | 524 KB    |            |   0% \nlibtiff-4.5.0        | 524 KB    | ########## | 100% \n\nca-certificates-2023 | 120 KB    |            |   0% \nca-certificates-2023 | 120 KB    | ########## | 100% \n\npip-21.2.2           | 1.8 MB    |            |   0% \npip-21.2.2           | 1.8 MB    | ########## | 100% \npip-21.2.2           | 1.8 MB    | ########## | 100% \n\njupyter_core-4.8.1   | 74 KB     |            |   0% \njupyter_core-4.8.1   | 74 KB     | ########## | 100% \n\nmatplotlib-3.3.4     | 26 KB     |            |   0% \nmatplotlib-3.3.4     | 26 KB     | ########## | 100% \n\nicu-58.2             | 10.5 MB   |            |   0% \nicu-58.2             | 10.5 MB   | ########## | 100% \nicu-58.2             | 10.5 MB   | ########## | 100% \n\ntk-8.6.12            | 3.0 MB    |            |   0% \ntk-8.6.12            | 3.0 MB    | ########## | 100% \ntk-8.6.12            | 3.0 MB    | ########## | 100% \n\nlibgfortran4-7.5.0   | 995 KB    |            |   0% \nlibgfortran4-7.5.0   | 995 KB    | ########## | 100% \n\nlibgomp-11.2.0       | 474 KB    |            |   0% \nlibgomp-11.2.0       | 474 KB    | ########## | 100% \n\nptyprocess-0.7.0     | 17 KB     |            |   0% \nptyprocess-0.7.0     | 17 KB     | ########## | 100% \n\nwheel-0.37.1         | 33 KB     |            |   0% \nwheel-0.37.1         | 33 KB     | ########## | 100% \n\nlibpng-1.6.37        | 278 KB    |            |   0% \nlibpng-1.6.37        | 278 KB    | ########## | 100% \n\nsqlite-3.23.1        | 808 KB    |            |   0% \nsqlite-3.23.1        | 808 KB    | ########## | 100% \n\npyqt-5.9.2           | 4.5 MB    |            |   0% \npyqt-5.9.2           | 4.5 MB    | ########## | 100% \npyqt-5.9.2           | 4.5 MB    | ########## | 100% \n\nparso-0.8.3          | 70 KB     |            |   0% \nparso-0.8.3          | 70 KB     | ########## | 100% \n\nsetuptools-58.0.4    | 788 KB    |            |   0% \nsetuptools-58.0.4    | 788 KB    | ########## | 100% \n\nsix-1.16.0           | 18 KB     |            |   0% \nsix-1.16.0           | 18 KB     | ########## | 100% \n\nqt-5.9.6             | 67.3 MB   |            |   0% \nqt-5.9.6             | 67.3 MB   | #6         |  16% \nqt-5.9.6             | 67.3 MB   | ###9       |  39% \nqt-5.9.6             | 67.3 MB   | ######2    |  63% \nqt-5.9.6             | 67.3 MB   | ########4  |  85% \nqt-5.9.6             | 67.3 MB   | ########## | 100% \n\ntraitlets-4.3.3      | 138 KB    |            |   0% \ntraitlets-4.3.3      | 138 KB    | ########## | 100% \n\nglib-2.63.1          | 2.9 MB    |            |   0% \nglib-2.63.1          | 2.9 MB    | ########## | 100% \nglib-2.63.1          | 2.9 MB    | ########## | 100% \n\nlcms2-2.12           | 312 KB    |            |   0% \nlcms2-2.12           | 312 KB    | ########## | 100% \n\nopenjpeg-2.4.0       | 331 KB    |            |   0% \nopenjpeg-2.4.0       | 331 KB    | ########## | 100% \n\nlibxml2-2.9.14       | 718 KB    |            |   0% \nlibxml2-2.9.14       | 718 KB    | ########## | 100% \n\nlibwebp-base-1.2.4   | 376 KB    |            |   0% \nlibwebp-base-1.2.4   | 376 KB    | ########## | 100% \n\nreadline-7.0         | 848 KB    |            |   0% \nreadline-7.0         | 848 KB    | ########## | 100% \n\nfontconfig-2.14.1    | 281 KB    |            |   0% \nfontconfig-2.14.1    | 281 KB    | ########## | 100% \n\nwcwidth-0.2.5        | 26 KB     |            |   0% \nwcwidth-0.2.5        | 26 KB     | ########## | 100% \n\npillow-8.3.1         | 637 KB    |            |   0% \npillow-8.3.1         | 637 KB    | ########## | 100% \n\nlibsodium-1.0.18     | 244 KB    |            |   0% \nlibsodium-1.0.18     | 244 KB    | ########## | 100% \n\nzlib-1.2.13          | 103 KB    |            |   0% \nzlib-1.2.13          | 103 KB    | ########## | 100% \n\npandas-1.1.5         | 8.2 MB    |            |   0% \npandas-1.1.5         | 8.2 MB    | ########## | 100% \npandas-1.1.5         | 8.2 MB    | ########## | 100% \n\nmatplotlib-base-3.3. | 5.1 MB    |            |   0% \nmatplotlib-base-3.3. | 5.1 MB    | ########## | 100% \nmatplotlib-base-3.3. | 5.1 MB    | ########## | 100% \n\nlibedit-3.1          | 151 KB    |            |   0% \nlibedit-3.1          | 151 KB    | ########## | 100% \n\ngst-plugins-base-1.1 | 4.8 MB    |            |   0% \ngst-plugins-base-1.1 | 4.8 MB    | ########## | 100% \ngst-plugins-base-1.1 | 4.8 MB    | ########## | 100% \n\njpeg-9e              | 240 KB    |            |   0% \njpeg-9e              | 240 KB    | ########## | 100% \n\nzstd-1.5.2           | 488 KB    |            |   0% \nzstd-1.5.2           | 488 KB    | ########## | 100% \n\nnumpy-base-1.19.2    | 4.1 MB    |            |   0% \nnumpy-base-1.19.2    | 4.1 MB    | ########## | 100% \nnumpy-base-1.19.2    | 4.1 MB    | ########## | 100% \n\ntornado-6.1          | 581 KB    |            |   0% \ntornado-6.1          | 581 KB    | ########## | 100% \n\nexpat-2.4.9          | 156 KB    |            |   0% \nexpat-2.4.9          | 156 KB    | ########## | 100% \n\njupyter_client-7.1.2 | 93 KB     |            |   0% \njupyter_client-7.1.2 | 93 KB     | ########## | 100% \n\nintel-openmp-2022.1. | 4.5 MB    |            |   0% \nintel-openmp-2022.1. | 4.5 MB    | ########## | 100% \nintel-openmp-2022.1. | 4.5 MB    | ########## | 100% \n\nprompt-toolkit-3.0.2 | 259 KB    |            |   0% \nprompt-toolkit-3.0.2 | 259 KB    | ########## | 100% \n\ndecorator-5.1.1      | 12 KB     |            |   0% \ndecorator-5.1.1      | 12 KB     | ########## | 100% \n\n_openmp_mutex-5.1    | 21 KB     |            |   0% \n_openmp_mutex-5.1    | 21 KB     | ########## | 100% \n\npexpect-4.8.0        | 53 KB     |            |   0% \npexpect-4.8.0        | 53 KB     | ########## | 100% \n\nthreadpoolctl-2.2.0  | 16 KB     |            |   0% \nthreadpoolctl-2.2.0  | 16 KB     | ########## | 100% \n\njedi-0.17.0          | 780 KB    |            |   0% \njedi-0.17.0          | 780 KB    | ########## | 100% \njedi-0.17.0          | 780 KB    | ########## | 100% \n\nipython-7.16.1       | 999 KB    |            |   0% \nipython-7.16.1       | 999 KB    | ########## | 100% \nipython-7.16.1       | 999 KB    | ########## | 100% \n\npcre-8.45            | 207 KB    |            |   0% \npcre-8.45            | 207 KB    | ########## | 100% \n\nmkl-service-2.3.0    | 52 KB     |            |   0% \nmkl-service-2.3.0    | 52 KB     | ########## | 100% \n\nlibgcc-ng-11.2.0     | 5.3 MB    |            |   0% \nlibgcc-ng-11.2.0     | 5.3 MB    | ########## | 100% \nlibgcc-ng-11.2.0     | 5.3 MB    | ########## | 100% \n\ncycler-0.11.0        | 12 KB     |            |   0% \ncycler-0.11.0        | 12 KB     | ########## | 100% \n\nsip-4.19.8           | 274 KB    |            |   0% \nsip-4.19.8           | 274 KB    | ########## | 100% \n\npython-3.6.2         | 23.6 MB   |            |   0% \npython-3.6.2         | 23.6 MB   | #####      |  50% \npython-3.6.2         | 23.6 MB   | ########## | 100% \n\npyzmq-22.2.1         | 454 KB    |            |   0% \npyzmq-22.2.1         | 454 KB    | ########## | 100% \n\npickleshare-0.7.5    | 13 KB     |            |   0% \npickleshare-0.7.5    | 13 KB     | ########## | 100% \n\nncurses-6.0          | 781 KB    |            |   0% \nncurses-6.0          | 781 KB    | ########## | 100% \nncurses-6.0          | 781 KB    | ########## | 100% \n\nnumpy-1.19.2         | 22 KB     |            |   0% \nnumpy-1.19.2         | 22 KB     | ########## | 100% \n\nlibgfortran-ng-7.5.0 | 22 KB     |            |   0% \nlibgfortran-ng-7.5.0 | 22 KB     | ########## | 100% \n\ncertifi-2021.5.30    | 139 KB    |            |   0% \ncertifi-2021.5.30    | 139 KB    | ########## | 100% \n\nscikit-learn-0.24.2  | 5.2 MB    |            |   0% \nscikit-learn-0.24.2  | 5.2 MB    | ########## | 100% \nscikit-learn-0.24.2  | 5.2 MB    | ########## | 100% \n\nolefile-0.46         | 48 KB     |            |   0% \nolefile-0.46         | 48 KB     | ########## | 100% \n\nmkl_fft-1.3.0        | 170 KB    |            |   0% \nmkl_fft-1.3.0        | 170 KB    | ########## | 100% \n\ndbus-1.13.18         | 504 KB    |            |   0% \ndbus-1.13.18         | 504 KB    | ########## | 100% \n\nlibffi-3.2.1         | 48 KB     |            |   0% \nlibffi-3.2.1         | 48 KB     | ########## | 100% \n\npytz-2021.3          | 171 KB    |            |   0% \npytz-2021.3          | 171 KB    | ########## | 100% \n\nlz4-c-1.9.4          | 154 KB    |            |   0% \nlz4-c-1.9.4          | 154 KB    | ########## | 100% \n\nblas-1.0             | 6 KB      |            |   0% \nblas-1.0             | 6 KB      | ########## | 100% \n\nipykernel-5.3.4      | 181 KB    |            |   0% \nipykernel-5.3.4      | 181 KB    | ########## | 100% \n\nmkl_random-1.1.1     | 327 KB    |            |   0% \nmkl_random-1.1.1     | 327 KB    | ########## | 100% \n\njoblib-1.0.1         | 208 KB    |            |   0% \njoblib-1.0.1         | 208 KB    | ########## | 100% \n\nnest-asyncio-1.5.1   | 10 KB     |            |   0% \nnest-asyncio-1.5.1   | 10 KB     | ########## | 100% \n\ngstreamer-1.14.0     | 3.1 MB    |            |   0% \ngstreamer-1.14.0     | 3.1 MB    | ########## | 100% \n\n_libgcc_mutex-0.1    | 3 KB      |            |   0% \n_libgcc_mutex-0.1    | 3 KB      | ########## | 100% \n\npython-dateutil-2.8. | 233 KB    |            |   0% \npython-dateutil-2.8. | 233 KB    | ########## | 100% \n\nscipy-1.5.2          | 14.4 MB   |            |   0% \nscipy-1.5.2          | 14.4 MB   | #######5   |  76% \nscipy-1.5.2          | 14.4 MB   | ########## | 100% \n\nlibstdcxx-ng-11.2.0  | 4.7 MB    |            |   0% \nlibstdcxx-ng-11.2.0  | 4.7 MB    | ########## | 100% \nlibstdcxx-ng-11.2.0  | 4.7 MB    | ########## | 100% \n\nxz-5.2.10            | 429 KB    |            |   0% \nxz-5.2.10            | 429 KB    | ########## | 100% \n\nlibxcb-1.15          | 505 KB    |            |   0% \nlibxcb-1.15          | 505 KB    | ########## | 100% \n\nipython_genutils-0.2 | 27 KB     |            |   0% \nipython_genutils-0.2 | 27 KB     | ########## | 100% \nPreparing transaction: ...working... done\nVerifying transaction: ...working... done\nExecuting transaction: ...working... \n\n    Installed package of scikit-learn can be accelerated using scikit-learn-intelex.\n    More details are available here: https://intel.github.io/scikit-learn-intelex\n\n    For example:\n\n        $ conda install scikit-learn-intelex\n        $ python -m sklearnex my_application.py\n\n    \n\ndone\nInstalling pip dependencies: ...working... \nRan pip subprocess with arguments:\n['/azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.lm7cnlig.requirements.txt']\nPip subprocess output:\nCollecting azureml-defaults\n  Downloading azureml_defaults-1.49.0-py3-none-any.whl (2.0 kB)\nCollecting pyarrow\n  Downloading pyarrow-6.0.1-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.6 MB)\nCollecting azureml-defaults\n  Downloading azureml_defaults-1.48.0-py3-none-any.whl (2.0 kB)\nCollecting azureml-dataset-runtime[fuse]~=1.48.0\n  Downloading azureml_dataset_runtime-1.48.0-py3-none-any.whl (2.2 kB)\nCollecting azureml-defaults\n  Downloading azureml_defaults-1.47.0-py3-none-any.whl (2.0 kB)\nCollecting json-logging-py==0.2\n  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\nCollecting azureml-inference-server-http~=0.7.2\n  Downloading azureml_inference_server_http-0.7.7-py3-none-any.whl (56 kB)\nCollecting configparser==3.7.4\n  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\nCollecting azureml-dataset-runtime[fuse]~=1.47.0\n  Downloading azureml_dataset_runtime-1.47.0-py3-none-any.whl (2.2 kB)\nCollecting azureml-core~=1.47.0\n  Downloading azureml_core-1.47.0-py3-none-any.whl (3.1 MB)\nRequirement already satisfied: numpy>=1.16.6 in /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/lib/python3.6/site-packages (from pyarrow->-r /azureml-environment-setup/condaenv.lm7cnlig.requirements.txt (line 2)) (1.19.2)\nCollecting PyJWT<3.0.0\n  Downloading PyJWT-2.4.0-py3-none-any.whl (18 kB)\nCollecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<41\n  Downloading cryptography-39.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (4.2 MB)\nCollecting azure-mgmt-containerregistry<11,>=8.2.0\n  Downloading azure_mgmt_containerregistry-10.0.0-py3-none-any.whl (1.2 MB)\nCollecting SecretStorage<4.0.0\n  Downloading SecretStorage-3.3.3-py3-none-any.whl (15 kB)\nCollecting azure-mgmt-resource<22.0.0,>=15.0.0\n  Downloading azure_mgmt_resource-21.1.0-py3-none-any.whl (1.8 MB)\nCollecting jsonpickle<3.0.0\n  Downloading jsonpickle-2.2.0-py2.py3-none-any.whl (39 kB)\nCollecting paramiko<3.0.0,>=2.0.8\n  Downloading paramiko-2.12.0-py2.py3-none-any.whl (213 kB)\nCollecting humanfriendly<11.0,>=4.7\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\nCollecting msal-extensions<=1.0.0,>=0.3.0\n  Downloading msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB)\nCollecting backports.tempfile\n  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\nCollecting msrest<=0.7.1,>=0.5.1\n  Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\nCollecting packaging<22.0,>=20.0\n  Downloading packaging-21.3-py3-none-any.whl (40 kB)\nCollecting azure-graphrbac<1.0.0,>=0.40.0\n  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\nCollecting adal<=1.2.7,>=1.2.0\n  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\nCollecting pathspec<1.0.0\n  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\nCollecting azure-mgmt-keyvault<11.0.0,>=0.40.0\n  Downloading azure_mgmt_keyvault-10.0.0-py3-none-any.whl (489 kB)\nCollecting ndg-httpsclient<=0.5.1\n  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.7.3 in /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/lib/python3.6/site-packages (from azureml-core~=1.47.0->azureml-defaults->-r /azureml-environment-setup/condaenv.lm7cnlig.requirements.txt (line 1)) (2.8.2)\nCollecting argcomplete<3\n  Downloading argcomplete-2.0.0-py2.py3-none-any.whl (37 kB)\nCollecting azure-mgmt-authorization<3,>=0.40.0\n  Downloading azure_mgmt_authorization-2.0.0-py2.py3-none-any.whl (465 kB)\nCollecting azure-common<2.0.0,>=1.1.12\n  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\nCollecting pyopenssl<23.0.0\n  Downloading pyOpenSSL-22.1.0-py3-none-any.whl (57 kB)\nCollecting azure-core<2.0.0\n  Downloading azure_core-1.24.2-py3-none-any.whl (178 kB)\nCollecting msal<2.0.0,>=1.15.0\n  Downloading msal-1.21.0-py2.py3-none-any.whl (89 kB)\nCollecting azure-mgmt-storage<21.0.0,>=16.0.0\n  Downloading azure_mgmt_storage-20.0.0-py3-none-any.whl (2.0 MB)\nCollecting msrestazure<=0.6.4,>=0.4.33\n  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\nCollecting jmespath<2.0.0\n  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\nCollecting pkginfo\n  Downloading pkginfo-1.9.6-py3-none-any.whl (30 kB)\nCollecting docker<7.0.0\n  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\nCollecting urllib3<2.0.0,>=1.23\n  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\nCollecting requests[socks]<3.0.0,>=2.19.1\n  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\nCollecting contextlib2<22.0.0\n  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\nCollecting knack~=0.10.0\n  Downloading knack-0.10.1-py3-none-any.whl (61 kB)\nRequirement already satisfied: pytz in /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/lib/python3.6/site-packages (from azureml-core~=1.47.0->azureml-defaults->-r /azureml-environment-setup/condaenv.lm7cnlig.requirements.txt (line 1)) (2021.3)\nCollecting importlib-metadata<5,>=0.23\n  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\nRequirement already satisfied: six>=1.11.0 in /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/lib/python3.6/site-packages (from azure-core<2.0.0->azureml-core~=1.47.0->azureml-defaults->-r /azureml-environment-setup/condaenv.lm7cnlig.requirements.txt (line 1)) (1.16.0)\nCollecting typing-extensions>=4.0.1\n  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\nCollecting azure-mgmt-core<2.0.0,>=1.2.0\n  Downloading azure_mgmt_core-1.3.2-py3-none-any.whl (26 kB)\nCollecting azureml-dataprep<4.6.0a,>=4.5.0a\n  Downloading azureml_dataprep-4.5.7-py3-none-any.whl (43.4 MB)\nCollecting fusepy<4.0.0,>=3.0.1\n  Downloading fusepy-3.0.1.tar.gz (11 kB)\nCollecting pyyaml<7.0.0,>=5.1.0\n  Downloading PyYAML-6.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (603 kB)\nCollecting dotnetcore2<4.0.0,>=3.0.0\n  Downloading dotnetcore2-3.1.23-py3-none-manylinux1_x86_64.whl (31.1 MB)\nCollecting azureml-dataprep-native<39.0.0,>=38.0.0\n  Downloading azureml_dataprep_native-38.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\nCollecting cloudpickle<3.0.0,>=1.1.0\n  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\nCollecting jsonschema\n  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\nCollecting azureml-dataprep-rslex~=2.11.0dev0\n  Downloading azureml_dataprep_rslex-2.11.4-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.3 MB)\nCollecting azure-identity==1.7.0\n  Downloading azure_identity-1.7.0-py2.py3-none-any.whl (129 kB)\nCollecting msal-extensions<=1.0.0,>=0.3.0\n  Downloading msal_extensions-0.3.1-py2.py3-none-any.whl (18 kB)\nCollecting inference-schema~=1.4.0\n  Downloading inference_schema-1.4.2.1-py3-none-any.whl (21 kB)\nCollecting flask-cors~=3.0.1\n  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\nCollecting gunicorn==20.1.0\n  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\nCollecting opencensus-ext-azure~=1.1.0\n  Downloading opencensus_ext_azure-1.1.8-py2.py3-none-any.whl (42 kB)\nRequirement already satisfied: setuptools>=3.0 in /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/lib/python3.6/site-packages (from gunicorn==20.1.0->azureml-inference-server-http~=0.7.2->azureml-defaults->-r /azureml-environment-setup/condaenv.lm7cnlig.requirements.txt (line 1)) (58.0.4)\nCollecting cffi>=1.12\n  Downloading cffi-1.15.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (402 kB)\nCollecting pycparser\n  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\nCollecting websocket-client>=0.32.0\n  Downloading websocket_client-1.3.1-py3-none-any.whl (54 kB)\nCollecting distro>=1.2.0\n  Downloading distro-1.8.0-py3-none-any.whl (20 kB)\nCollecting Flask>=0.9\n  Downloading Flask-2.0.3-py3-none-any.whl (95 kB)\nCollecting itsdangerous>=2.0\n  Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)\nCollecting click>=7.1.2\n  Downloading click-8.0.4-py3-none-any.whl (97 kB)\nCollecting Jinja2>=3.0\n  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\nCollecting Werkzeug>=2.0\n  Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\nCollecting zipp>=0.5\n  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\nCollecting wrapt<=1.12.1,>=1.11.1\n  Downloading wrapt-1.12.1.tar.gz (27 kB)\nCollecting MarkupSafe>=2.0\n  Downloading MarkupSafe-2.0.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (30 kB)\nRequirement already satisfied: pygments in /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/lib/python3.6/site-packages (from knack~=0.10.0->azureml-core~=1.47.0->azureml-defaults->-r /azureml-environment-setup/condaenv.lm7cnlig.requirements.txt (line 1)) (2.11.2)\nCollecting tabulate\n  Downloading tabulate-0.8.10-py3-none-any.whl (29 kB)\nCollecting portalocker<3,>=1.0\n  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\nCollecting isodate>=0.6.0\n  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\nRequirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/lib/python3.6/site-packages (from msrest<=0.7.1,>=0.5.1->azureml-core~=1.47.0->azureml-defaults->-r /azureml-environment-setup/condaenv.lm7cnlig.requirements.txt (line 1)) (2021.5.30)\nCollecting requests-oauthlib>=0.5.0\n  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\nCollecting pyasn1>=0.1.1\n  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\nCollecting psutil>=5.6.3\n  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\nCollecting opencensus<1.0.0,>=0.11.1\n  Downloading opencensus-0.11.1-py2.py3-none-any.whl (128 kB)\nCollecting google-api-core<3.0.0,>=1.0.0\n  Downloading google_api_core-2.8.2-py3-none-any.whl (114 kB)\nCollecting opencensus-context>=0.1.3\n  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\nCollecting google-auth<3.0dev,>=1.25.0\n  Downloading google_auth-2.16.1-py2.py3-none-any.whl (177 kB)\nCollecting googleapis-common-protos<2.0dev,>=1.56.2\n  Downloading googleapis_common_protos-1.56.3-py2.py3-none-any.whl (211 kB)\nCollecting protobuf<5.0.0dev,>=3.15.0\n  Downloading protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\nCollecting cachetools<6.0,>=2.0.0\n  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\nCollecting rsa<5,>=3.1.4\n  Downloading rsa-4.9-py3-none-any.whl (34 kB)\nCollecting pyasn1-modules>=0.2.1\n  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\nCollecting contextvars\n  Downloading contextvars-2.4.tar.gz (9.6 kB)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/lib/python3.6/site-packages (from packaging<22.0,>=20.0->azureml-core~=1.47.0->azureml-defaults->-r /azureml-environment-setup/condaenv.lm7cnlig.requirements.txt (line 1)) (3.0.4)\nCollecting bcrypt>=3.1.3\n  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (593 kB)\nCollecting pynacl>=1.0.1\n  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\nCollecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<41\n  Downloading cryptography-38.0.4-cp36-abi3-manylinux_2_28_x86_64.whl (4.2 MB)\nCollecting idna<4,>=2.5\n  Downloading idna-3.4-py3-none-any.whl (61 kB)\nCollecting charset-normalizer~=2.0.0\n  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\nCollecting oauthlib>=3.0.0\n  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\nCollecting PySocks!=1.5.7,>=1.5.6\n  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\nCollecting jeepney>=0.6\n  Downloading jeepney-0.7.1-py3-none-any.whl (54 kB)\nCollecting dataclasses\n  Downloading dataclasses-0.8-py3-none-any.whl (19 kB)\nCollecting backports.weakref\n  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\nCollecting immutables>=0.9\n  Downloading immutables-0.19-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (116 kB)\nCollecting attrs>=17.4.0\n  Downloading attrs-22.2.0-py3-none-any.whl (60 kB)\nCollecting pyrsistent>=0.14.0\n  Downloading pyrsistent-0.18.0-cp36-cp36m-manylinux1_x86_64.whl (117 kB)\nBuilding wheels for collected packages: json-logging-py, fusepy, wrapt, contextvars\n  Building wheel for json-logging-py (setup.py): started\n  Building wheel for json-logging-py (setup.py): finished with status 'done'\n  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3924 sha256=2dca870c6afc7a2e26246d6d7cc8686a2ffc638b782bd9c730a4be8ba584c464\n  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\n  Building wheel for fusepy (setup.py): started\n  Building wheel for fusepy (setup.py): finished with status 'done'\n  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10503 sha256=5a312119e309c2ce4042972c99f90314401d9469dd088a4c4c5099bafb695be9\n  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n  Building wheel for wrapt (setup.py): started\n  Building wheel for wrapt (setup.py): finished with status 'done'\n  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=76174 sha256=8db960e481d81b336987ec9b1181abee8e7544b28463394c2b839e9a50ae1ff1\n  Stored in directory: /root/.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\n  Building wheel for contextvars (setup.py): started\n  Building wheel for contextvars (setup.py): finished with status 'done'\n  Created wheel for contextvars: filename=contextvars-2.4-py3-none-any.whl size=7681 sha256=6bd4d0767007ac4994606ec86d36f98822bbddcddd279d425656a839323d67f2\n  Stored in directory: /root/.cache/pip/wheels/41/11/53/911724983aa48deb94792432e14e518447212dd6c5477d49d3\nSuccessfully built json-logging-py fusepy wrapt contextvars\nInstalling collected packages: pycparser, cffi, urllib3, PyJWT, idna, cryptography, charset-normalizer, typing-extensions, requests, pyasn1, zipp, rsa, pyasn1-modules, protobuf, portalocker, oauthlib, msal, immutables, cachetools, requests-oauthlib, pyrsistent, msal-extensions, MarkupSafe, isodate, importlib-metadata, googleapis-common-protos, google-auth, distro, dataclasses, contextvars, azure-core, attrs, Werkzeug, pyyaml, opencensus-context, msrest, jsonschema, Jinja2, itsdangerous, google-api-core, dotnetcore2, cloudpickle, click, azureml-dataprep-rslex, azureml-dataprep-native, azure-identity, adal, wrapt, websocket-client, tabulate, PySocks, pyopenssl, pynacl, pyarrow, psutil, opencensus, msrestazure, jmespath, jeepney, Flask, bcrypt, backports.weakref, azureml-dataprep, azure-mgmt-core, azure-common, argcomplete, SecretStorage, pkginfo, pathspec, paramiko, packaging, opencensus-ext-azure, ndg-httpsclient, knack, jsonpickle, inference-schema, humanfriendly, gunicorn, fusepy, flask-cors, docker, contextlib2, backports.tempfile, azureml-dataset-runtime, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, azure-graphrbac, json-logging-py, configparser, azureml-inference-server-http, azureml-core, azureml-defaults\nSuccessfully installed Flask-2.0.3 Jinja2-3.0.3 MarkupSafe-2.0.1 PyJWT-2.4.0 PySocks-1.7.1 SecretStorage-3.3.3 Werkzeug-2.0.3 adal-1.2.7 argcomplete-2.0.0 attrs-22.2.0 azure-common-1.1.28 azure-core-1.24.2 azure-graphrbac-0.61.1 azure-identity-1.7.0 azure-mgmt-authorization-2.0.0 azure-mgmt-containerregistry-10.0.0 azure-mgmt-core-1.3.2 azure-mgmt-keyvault-10.0.0 azure-mgmt-resource-21.1.0 azure-mgmt-storage-20.0.0 azureml-core-1.47.0 azureml-dataprep-4.5.7 azureml-dataprep-native-38.0.0 azureml-dataprep-rslex-2.11.4 azureml-dataset-runtime-1.47.0 azureml-defaults-1.47.0 azureml-inference-server-http-0.7.7 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-4.0.1 cachetools-4.2.4 cffi-1.15.1 charset-normalizer-2.0.12 click-8.0.4 cloudpickle-2.2.1 configparser-3.7.4 contextlib2-21.6.0 contextvars-2.4 cryptography-38.0.4 dataclasses-0.8 distro-1.8.0 docker-5.0.3 dotnetcore2-3.1.23 flask-cors-3.0.10 fusepy-3.0.1 google-api-core-2.8.2 google-auth-2.16.1 googleapis-common-protos-1.56.3 gunicorn-20.1.0 humanfriendly-10.0 idna-3.4 immutables-0.19 importlib-metadata-4.8.3 inference-schema-1.4.2.1 isodate-0.6.1 itsdangerous-2.0.1 jeepney-0.7.1 jmespath-0.10.0 json-logging-py-0.2 jsonpickle-2.2.0 jsonschema-3.2.0 knack-0.10.1 msal-1.21.0 msal-extensions-0.3.1 msrest-0.7.1 msrestazure-0.6.4 ndg-httpsclient-0.5.1 oauthlib-3.2.2 opencensus-0.11.1 opencensus-context-0.1.3 opencensus-ext-azure-1.1.8 packaging-21.3 paramiko-2.12.0 pathspec-0.9.0 pkginfo-1.9.6 portalocker-2.7.0 protobuf-3.19.6 psutil-5.9.4 pyarrow-6.0.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycparser-2.21 pynacl-1.5.0 pyopenssl-22.1.0 pyrsistent-0.18.0 pyyaml-6.0 requests-2.27.1 requests-oauthlib-1.3.1 rsa-4.9 tabulate-0.8.10 typing-extensions-4.1.1 urllib3-1.26.14 websocket-client-1.3.1 wrapt-1.12.1 zipp-3.6.0\n\ndone\n#\n# To activate this environment, use\n#\n#     $ conda activate /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b\n#\n# To deactivate an active environment, use\n#\n#     $ conda deactivate\n\n\u001b[91m\n\n==> WARNING: A newer version of conda exists. <==\n  current version: 4.12.0\n  latest version: 23.1.0\n\nPlease update conda by running\n\n    $ conda update -n base -c defaults conda\n\n\n\u001b[0mWARNING: /root/.conda/pkgs does not exist\n\nRemoving intermediate container 4c1b4e83d23f\n ---> 7d7344c3d456\nStep 9/21 : ENV PATH /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/bin:$PATH\n ---> Running in fc0d0b66dcd7\nRemoving intermediate container fc0d0b66dcd7\n ---> dd9ceee22fbf\nStep 10/21 : COPY azureml-environment-setup/send_conda_dependencies.py azureml-environment-setup/send_conda_dependencies.py\n ---> c8e616ad6533\nStep 11/21 : RUN echo \"Copying environment context\"\n ---> Running in da7600075104\nCopying environment context\nRemoving intermediate container da7600075104\n ---> 36a1562bb625\nStep 12/21 : COPY azureml-environment-setup/environment_context.json azureml-environment-setup/environment_context.json\n ---> d1256ef04140\nStep 13/21 : RUN python /azureml-environment-setup/send_conda_dependencies.py -p /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b\n ---> Running in 4a3ce3865870\nReport materialized dependencies for the environment\nReading environment context\nExporting conda environment\nSending request with materialized conda environment details\nSuccessfully sent materialized environment details\nRemoving intermediate container 4a3ce3865870\n ---> 0dc353a892a6\nStep 14/21 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b\n ---> Running in c65011c5e551\nRemoving intermediate container c65011c5e551\n ---> b38ea2f7e71c\nStep 15/21 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/lib:$LD_LIBRARY_PATH\n ---> Running in 8f4fa885127e\nRemoving intermediate container 8f4fa885127e\n ---> 354c236c38ed\nStep 16/21 : ENV CONDA_DEFAULT_ENV=azureml_0c5a9aa2def4b3c2501c1f40287a356b CONDA_PREFIX=/azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b\n ---> Running in c0544a37db66\nRemoving intermediate container c0544a37db66\n ---> cbec21e32051\nStep 17/21 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n ---> 5244d5a9e736\nStep 18/21 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n ---> Running in 5d720e19fbf6\nRemoving intermediate container 5d720e19fbf6\n ---> 04cb90ef4e3b\nStep 19/21 : RUN rm -rf azureml-environment-setup\n ---> Running in 76c46248c473\nRemoving intermediate container 76c46248c473\n ---> 2e754e2bc604\nStep 20/21 : ENV AZUREML_ENVIRONMENT_IMAGE True\n ---> Running in 338cf07deed7\nRemoving intermediate container 338cf07deed7\n ---> f0b942a9ca98\nStep 21/21 : CMD [\"bash\"]\n ---> Running in 4e31c48525f6\nRemoving intermediate container 4e31c48525f6\n ---> 9f0abd18d61a\nSuccessfully built 9f0abd18d61a\nSuccessfully tagged 6acc10c0eb1c448092f9d5e10581d6fe.azurecr.io/azureml/azureml_eb4ae1f22a6b9a15bc42fb135660daf8:latest\nSuccessfully tagged 6acc10c0eb1c448092f9d5e10581d6fe.azurecr.io/azureml/azureml_eb4ae1f22a6b9a15bc42fb135660daf8:1\n2023/02/25 21:31:27 Successfully executed container: acb_step_0\n2023/02/25 21:31:27 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n2023/02/25 21:31:27 Pushing image: 6acc10c0eb1c448092f9d5e10581d6fe.azurecr.io/azureml/azureml_eb4ae1f22a6b9a15bc42fb135660daf8:1, attempt 1\nThe push refers to repository [6acc10c0eb1c448092f9d5e10581d6fe.azurecr.io/azureml/azureml_eb4ae1f22a6b9a15bc42fb135660daf8]\n2739f9d7cfd7: Preparing\n9c3b21583afd: Preparing\n1ac5dcee3042: Preparing\n51e586cb70db: Preparing\nb3aa82158944: Preparing\ne05099c3891a: Preparing\ncc96ae57071f: Preparing\n91a262c2fba1: Preparing\n9543295b843b: Preparing\n497a9d47ef52: Preparing\n2bcdf82aed44: Preparing\nb21e039321ee: Preparing\n445a2d2462f0: Preparing\n6e539e6b11c3: Preparing\nb67f8b8feccd: Preparing\n7e60813e02c4: Preparing\n0d66ccba1288: Preparing\n20b46ade1e43: Preparing\n21d33b1352c9: Preparing\naf7ed92504ae: Preparing\ne05099c3891a: Waiting\ncc96ae57071f: Waiting\n91a262c2fba1: Waiting\n9543295b843b: Waiting\n497a9d47ef52: Waiting\n2bcdf82aed44: Waiting\nb21e039321ee: Waiting\n445a2d2462f0: Waiting\n6e539e6b11c3: Waiting\nb67f8b8feccd: Waiting\n7e60813e02c4: Waiting\n0d66ccba1288: Waiting\n20b46ade1e43: Waiting\n21d33b1352c9: Waiting\naf7ed92504ae: Waiting\n51e586cb70db: Pushed\n9c3b21583afd: Pushed\nb3aa82158944: Pushed\n2739f9d7cfd7: Pushed\n9543295b843b: Pushed\ncc96ae57071f: Pushed\n1ac5dcee3042: Pushed\n497a9d47ef52: Pushed\nb21e039321ee: Pushed\n2bcdf82aed44: Pushed\n91a262c2fba1: Pushed\n7e60813e02c4: Pushed\n445a2d2462f0: Pushed\n6e539e6b11c3: Pushed\n0d66ccba1288: Pushed\n20b46ade1e43: Pushed\nb67f8b8feccd: Pushed\naf7ed92504ae: Pushed\n\n21d33b1352c9: Pushed\ne05099c3891a: Pushed\n1: digest: sha256:cfcd16d34d6bd0f1c77bc22ded6fecf58d9b1d44b9d6ea7ee1ee5d6affbaf08d size: 4514\n2023/02/25 21:33:19 Successfully pushed image: 6acc10c0eb1c448092f9d5e10581d6fe.azurecr.io/azureml/azureml_eb4ae1f22a6b9a15bc42fb135660daf8:1\n2023/02/25 21:33:19 Executing step ID: acb_step_2. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n2023/02/25 21:33:19 Pushing image: 6acc10c0eb1c448092f9d5e10581d6fe.azurecr.io/azureml/azureml_eb4ae1f22a6b9a15bc42fb135660daf8:latest, attempt 1\nThe push refers to repository [6acc10c0eb1c448092f9d5e10581d6fe.azurecr.io/azureml/azureml_eb4ae1f22a6b9a15bc42fb135660daf8]\n2739f9d7cfd7: Preparing\n9c3b21583afd: Preparing\n1ac5dcee3042: Preparing\n51e586cb70db: Preparing\nb3aa82158944: Preparing\ne05099c3891a: Preparing\ncc96ae57071f: Preparing\n91a262c2fba1: Preparing\n9543295b843b: Preparing\n497a9d47ef52: Preparing\n2bcdf82aed44: Preparing\nb21e039321ee: Preparing\n445a2d2462f0: Preparing\n6e539e6b11c3: Preparing\nb67f8b8feccd: Preparing\n7e60813e02c4: Preparing\n0d66ccba1288: Preparing\n20b46ade1e43: Preparing\n21d33b1352c9: Preparing\naf7ed92504ae: Preparing\ne05099c3891a: Waiting\ncc96ae57071f: Waiting\n91a262c2fba1: Waiting\n9543295b843b: Waiting\n497a9d47ef52: Waiting\n2bcdf82aed44: Waiting\nb21e039321ee: Waiting\n445a2d2462f0: Waiting\n6e539e6b11c3: Waiting\nb67f8b8feccd: Waiting\n7e60813e02c4: Waiting\n0d66ccba1288: Waiting\n20b46ade1e43: Waiting\n21d33b1352c9: Waiting\naf7ed92504ae: Waiting\n1ac5dcee3042: Layer already exists\n2739f9d7cfd7: Layer already exists\nb3aa82158944: Layer already exists\n9c3b21583afd: Layer already exists\ne05099c3891a: Layer already exists\n51e586cb70db: Layer already exists\ncc96ae57071f: Layer already exists\n91a262c2fba1: Layer already exists\n9543295b843b: Layer already exists\n2bcdf82aed44: Layer already exists\n497a9d47ef52: Layer already exists\nb21e039321ee: Layer already exists\n6e539e6b11c3: Layer already exists\n445a2d2462f0: Layer already exists\nb67f8b8feccd: Layer already exists\n7e60813e02c4: Layer already exists\n0d66ccba1288: Layer already exists\n21d33b1352c9: Layer already exists\naf7ed92504ae: Layer already exists\n20b46ade1e43: Layer already exists\nlatest: digest: sha256:cfcd16d34d6bd0f1c77bc22ded6fecf58d9b1d44b9d6ea7ee1ee5d6affbaf08d size: 4514\n2023/02/25 21:33:21 Successfully pushed image: 6acc10c0eb1c448092f9d5e10581d6fe.azurecr.io/azureml/azureml_eb4ae1f22a6b9a15bc42fb135660daf8:latest\n2023/02/25 21:33:21 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 153.916779)\n2023/02/25 21:33:21 Populating digests for step ID: acb_step_0...\n2023/02/25 21:33:23 Successfully populated digests for step ID: acb_step_0\n2023/02/25 21:33:23 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 112.370135)\n2023/02/25 21:33:23 Step ID: acb_step_2 marked as successful (elapsed time in seconds: 2.276983)\n2023/02/25 21:33:23 The following dependencies were found:\n2023/02/25 21:33:23 \n- image:\n    registry: 6acc10c0eb1c448092f9d5e10581d6fe.azurecr.io\n    repository: azureml/azureml_eb4ae1f22a6b9a15bc42fb135660daf8\n    tag: latest\n    digest: sha256:cfcd16d34d6bd0f1c77bc22ded6fecf58d9b1d44b9d6ea7ee1ee5d6affbaf08d\n  runtime-dependency:\n    registry: mcr.microsoft.com\n    repository: azureml/openmpi4.1.0-ubuntu20.04\n    tag: 20221101.v1\n    digest: sha256:4505a963b2d34a42b5eaef48b8142ca98123d05d3a95eee3fe57551570a70e3b\n  git: {}\n- image:\n    registry: 6acc10c0eb1c448092f9d5e10581d6fe.azurecr.io\n    repository: azureml/azureml_eb4ae1f22a6b9a15bc42fb135660daf8\n    tag: \"1\"\n    digest: sha256:cfcd16d34d6bd0f1c77bc22ded6fecf58d9b1d44b9d6ea7ee1ee5d6affbaf08d\n  runtime-dependency:\n    registry: mcr.microsoft.com\n    repository: azureml/openmpi4.1.0-ubuntu20.04\n    tag: 20221101.v1\n    digest: sha256:4505a963b2d34a42b5eaef48b8142ca98123d05d3a95eee3fe57551570a70e3b\n  git: {}\n\n\nRun ID: ch1 was successful after 4m33s\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677276184528
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for run in pipeline_run.get_children():\r\n",
        "    print(run.name, ':')\r\n",
        "    metrics = run.get_metrics()\r\n",
        "    for metric_name in metrics:\r\n",
        "        print('\\t',metric_name, \":\", metrics[metric_name])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677276187361
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "\r\n",
        "# Create a folder for the deployment files\r\n",
        "deployment_folder = './titanic_service'\r\n",
        "os.makedirs(deployment_folder, exist_ok=True)\r\n",
        "print(deployment_folder, 'folder created.')\r\n",
        "\r\n",
        "# Set path for scoring script\r\n",
        "script_file = 'score_titanic.py'\r\n",
        "script_path = os.path.join(deployment_folder,script_file)\r\n",
        "     "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677276187650
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $script_path\r\n",
        "import json\r\n",
        "import joblib\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "from azureml.core import Workspace, Dataset, Datastore\r\n",
        "\r\n",
        "# Called when the service is loaded\r\n",
        "def init():\r\n",
        "    global model\r\n",
        "    # Get the path to the deployed model file and load it\r\n",
        "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'titanic_model.pkl')\r\n",
        "    model = joblib.load(model_path)\r\n",
        "\r\n",
        "    # Workspace Information\r\n",
        "    subscription_id = '71fa0172-ce90-403c-94a9-14ce1e88f56a'\r\n",
        "    resource_group = 'rg_eastus_44930_1_1677358905717'\r\n",
        "    workspace_name = 'testerinos'\r\n",
        "\r\n",
        "    datastore = Datastore.get(workspace, \"workspaceblobstore\")\r\n",
        "    dataset = Dataset.File.from_files(path=(datastore, 'titanic-data/scaler.pkl'))\r\n",
        "    mounted_path = dataset.mount()\r\n",
        "    dataset.download(target_path='.')\r\n",
        "\r\n",
        "# Called when a request is received\r\n",
        "def run(raw_data):\r\n",
        "    # Get the input data as a numpy array\r\n",
        "    data = np.array(json.loads(raw_data)['data'])\r\n",
        "\r\n",
        "    scaler = load(open('scaler.pkl', 'rb'))\r\n",
        "\r\n",
        "    data = scalar.transform(data)\r\n",
        "\r\n",
        "    # Get a prediction from the model\r\n",
        "    predictions = model.predict(data)\r\n",
        "    # Get the corresponding classname for each prediction (0 or 1)\r\n",
        "    classnames = ['Non-Survived', 'Survived']\r\n",
        "    predicted_classes = []\r\n",
        "    for prediction in predictions:\r\n",
        "        predicted_classes.append(classnames[prediction])\r\n",
        "    # Return the predictions as JSON\r\n",
        "    return json.dumps(predicted_classes)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ws.models['titanic_model']\r\n",
        "print(model.name, 'version', model.version)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677276188191
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\r\n",
        "from azureml.core.model import InferenceConfig\r\n",
        "from azureml.core.webservice import AciWebservice\r\n",
        "from azureml.core import Model\r\n",
        "\r\n",
        "# Configure the scoring environment\r\n",
        "service_env = Environment.get(workspace=ws, name=\"AzureML-sklearn-0.24.1-ubuntu18.04-py37-cpu-inference\")\r\n",
        "service_env.inferencing_stack_version=\"latest\"\r\n",
        "\r\n",
        "inference_config = InferenceConfig(source_directory=deployment_folder,\r\n",
        "                                   entry_script=script_file,\r\n",
        "                                   environment=service_env)\r\n",
        "\r\n",
        "# Configure the web service container\r\n",
        "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\r\n",
        "\r\n",
        "# Deploy the model as a service\r\n",
        "print('Deploying model...')\r\n",
        "service_name = \"titanic-service\"\r\n",
        "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, overwrite=True)\r\n",
        "service.wait_for_deployment(True)\r\n",
        "print(service.state)\r\n",
        "     "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677276272327
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for webservice_name in ws.webservices:\r\n",
        "    print(webservice_name)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677276273312
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Invoke Endpoint\r\n",
        "\r\n",
        "import json\r\n",
        "\r\n",
        "x_new = [[22,0,7.25],[54,1,52]]\r\n",
        "\r\n",
        "# Convert the array to a serializable list in a JSON document\r\n",
        "input_json = json.dumps({\"data\": x_new})\r\n",
        "\r\n",
        "# Call the web service, passing the input data (the web service will also accept the data in binary format)\r\n",
        "predictions = service.run(input_data = input_json)\r\n",
        "\r\n",
        "# Get the predicted class - it'll be the first (and only) one.\r\n",
        "predicted_classes = json.loads(predictions)\r\n",
        "\r\n",
        "for i in range(len(x_new)):\r\n",
        "    print (\"Passenger {}\".format(x_new[i]), predicted_classes[i] )\r\n",
        "     "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677276552032
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "service.delete()\r\n",
        "print ('Service deleted.')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677276569353
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Research/References:\r\n",
        "\r\n",
        "- https://machinelearningmastery.com/how-to-save-and-load-models-and-data-preparation-in-scikit-learn-for-later-use/"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
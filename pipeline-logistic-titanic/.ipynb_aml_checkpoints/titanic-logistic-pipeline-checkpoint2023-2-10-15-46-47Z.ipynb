{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\r\n",
        "\r\n",
        "# Motivation"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\r\n",
        "\r\n",
        "import azureml.core\r\n",
        "from azureml.core import Workspace, Dataset, Datastore\r\n",
        "from azureml.data.datapath import DataPath\r\n",
        "\r\n",
        "import os"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677384132279
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to Workspace"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "# Load the workspace from the saved config file\r\n",
        "ws = Workspace.from_config()\r\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ready to use Azure ML 1.48.0 to work with testerinois\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1677382889029
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "\r\n",
        "default_ds = ws.get_default_datastore()\r\n",
        "\r\n",
        "if 'titanic dataset' not in ws.datasets:\r\n",
        "    Dataset.File.upload_directory(src_dir='data',\r\n",
        "                              target=DataPath(default_ds, 'titanic-data/')\r\n",
        "                              )\r\n",
        "\r\n",
        "    #Create a tabular dataset from the path on the datastore (this may take a short while)\r\n",
        "    tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'titanic-data/titanic.csv'))\r\n",
        "\r\n",
        "    # Register the tabular dataset\r\n",
        "    try:\r\n",
        "        tab_data_set = tab_data_set.register(workspace=ws, \r\n",
        "                                name='titanic dataset',\r\n",
        "                                description='titanic data',\r\n",
        "                                tags = {'format':'CSV'},\r\n",
        "                                create_new_version=True)\r\n",
        "        print('Dataset registered.')\r\n",
        "    except Exception as ex:\r\n",
        "        print(ex)\r\n",
        "else:\r\n",
        "    print('Dataset already registered.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Validating arguments.\nArguments validated.\nUploading file to titanic-data/\nUploading an estimated of 3 files\nUploading data/.amlignore\nUploaded data/.amlignore, 1 files out of an estimated total of 3\nUploading data/.amlignore.amltmp\nUploaded data/.amlignore.amltmp, 2 files out of an estimated total of 3\nUploading data/titanic.csv\nUploaded data/titanic.csv, 3 files out of an estimated total of 3\nUploaded 3 files\nCreating new dataset\nDataset registered.\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677382897450
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "# Create a folder for the pipeline step files\r\n",
        "experiment_folder = 'titanic_pipeline'\r\n",
        "os.makedirs(experiment_folder, exist_ok=True)\r\n",
        "\r\n",
        "print(experiment_folder)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "titanic_pipeline\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677382897724
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/prep_titanic.py\r\n",
        "# Import libraries\r\n",
        "import os\r\n",
        "import argparse\r\n",
        "import pandas as pd\r\n",
        "import joblib\r\n",
        "from azureml.core import Run\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "from azureml.core import Workspace, Dataset, Datastore\r\n",
        "from azureml.data.datapath import DataPath\r\n",
        "\r\n",
        "\r\n",
        "# Get parameters\r\n",
        "parser = argparse.ArgumentParser()\r\n",
        "parser.add_argument(\"--input-data\", type=str, dest='raw_dataset_id', help='raw dataset')\r\n",
        "parser.add_argument('--prepped-data', type=str, dest='prepped_data', default='prepped_data', help='Folder for results')\r\n",
        "args = parser.parse_args()\r\n",
        "save_folder = args.prepped_data\r\n",
        "\r\n",
        "## UPDATE depending on the resource group. Need to use service principals for proper auth\r\n",
        "subscription_id = '71fa0172-ce90-403c-94a9-14ce1e88f56a'\r\n",
        "resource_group = 'rg_eastus_44930_1_1677382226452'\r\n",
        "#workspace_name = 'testerinos'\r\n",
        "workspace_name = 'testerinois'\r\n",
        "\r\n",
        "\r\n",
        "# when this line executes, Azure will ask to authenticate... just need a better way to do it automatically as opposed to checking the userlogs\r\n",
        "ws= Workspace(subscription_id, resource_group, workspace_name)\r\n",
        "\r\n",
        "default_ds = ws.get_default_datastore()\r\n",
        "\r\n",
        "\r\n",
        "# Get the experiment run context\r\n",
        "run = Run.get_context()\r\n",
        "\r\n",
        "# load the data (passed as an input dataset)\r\n",
        "print(\"Loading Data...\")\r\n",
        "df = run.input_datasets['raw_data'].to_pandas_dataframe()\r\n",
        "\r\n",
        "# Log raw row count\r\n",
        "row_count = (len(df))\r\n",
        "run.log('raw_rows', row_count)\r\n",
        "\r\n",
        "# remove nulls\r\n",
        "df = df.dropna()\r\n",
        "\r\n",
        "# Normalize the numeric columns\r\n",
        "# Scaling isn't necessary for decision trees\r\n",
        "scaler = MinMaxScaler()\r\n",
        "num_cols = ['Age','Fare']\r\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])\r\n",
        "\r\n",
        "df['Sex'] = df['Sex'].replace({'male':1,'female':0})\r\n",
        "\r\n",
        "# Log processed rows\r\n",
        "row_count = (len(df))\r\n",
        "run.log('processed_rows', row_count)\r\n",
        "\r\n",
        "# Save the prepped data\r\n",
        "print(\"Saving Data...\")\r\n",
        "os.makedirs(save_folder, exist_ok=True)\r\n",
        "save_path = os.path.join(save_folder,'data.csv')\r\n",
        "df.to_csv(save_path, index=False, header=True)\r\n",
        "\r\n",
        "# Saving Scalar File\r\n",
        "os.makedirs('outputs', exist_ok=True)\r\n",
        "scaler_file = os.path.join('outputs', 'titanic_scaler.pkl')\r\n",
        "joblib.dump(value=scaler, filename=scaler_file)\r\n",
        "\r\n",
        "\r\n",
        "default_ds = ws.get_default_datastore()\r\n",
        "folder_data = Dataset.File.upload_directory(src_dir='outputs',\r\n",
        "                              target=DataPath(default_ds, 'titanic-data/')\r\n",
        "                              )\r\n",
        "\r\n",
        "try:\r\n",
        "    folder_data.register(workspace=ws, name='titanic_scaler.pkl')\r\n",
        "except:\r\n",
        "    continue\r\n",
        "\r\n",
        "# End the run\r\n",
        "run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting titanic_pipeline/prep_titanic.py\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/train_titanic.py\r\n",
        "# Import libraries\r\n",
        "from azureml.core import Run, Model\r\n",
        "import argparse\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import joblib\r\n",
        "import os\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.metrics import roc_auc_score\r\n",
        "from sklearn.metrics import roc_curve\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "# Get parameters\r\n",
        "parser = argparse.ArgumentParser()\r\n",
        "parser.add_argument(\"--training-data\", type=str, dest='training_data', help='training data')\r\n",
        "args = parser.parse_args()\r\n",
        "training_data = args.training_data\r\n",
        "\r\n",
        "# Get the experiment run context\r\n",
        "run = Run.get_context()\r\n",
        "\r\n",
        "# load the prepared data file in the training folder\r\n",
        "print(\"Loading Data...\")\r\n",
        "file_path = os.path.join(training_data,'data.csv')\r\n",
        "titanic = pd.read_csv(file_path)\r\n",
        "\r\n",
        "# Separate features and labels\r\n",
        "X, y = titanic[['Age','Sex','Fare']].values, titanic['Survived'].values\r\n",
        "\r\n",
        "# Split data into training set and test set\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\r\n",
        "\r\n",
        "# Train adecision tree model\r\n",
        "print('Training a decision tree model...')\r\n",
        "model = LogisticRegression(random_state = 42).fit(X_train, y_train)\r\n",
        "\r\n",
        "# calculate accuracy\r\n",
        "y_hat = model.predict(X_test)\r\n",
        "acc = np.average(y_hat == y_test)\r\n",
        "print('Accuracy:', acc)\r\n",
        "run.log('Accuracy', np.float(acc))\r\n",
        "\r\n",
        "# calculate AUC\r\n",
        "y_scores = model.predict_proba(X_test)\r\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\r\n",
        "print('AUC: ' + str(auc))\r\n",
        "run.log('AUC', np.float(auc))\r\n",
        "\r\n",
        "# plot ROC curve\r\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\r\n",
        "fig = plt.figure(figsize=(6, 4))\r\n",
        "# Plot the diagonal 50% line\r\n",
        "plt.plot([0, 1], [0, 1], 'k--')\r\n",
        "# Plot the FPR and TPR achieved by our model\r\n",
        "plt.plot(fpr, tpr)\r\n",
        "plt.xlabel('False Positive Rate')\r\n",
        "plt.ylabel('True Positive Rate')\r\n",
        "plt.title('ROC Curve')\r\n",
        "run.log_image(name = \"ROC\", plot = fig)\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# Save the trained model in the outputs folder\r\n",
        "print(\"Saving model...\")\r\n",
        "os.makedirs('outputs', exist_ok=True)\r\n",
        "model_file = os.path.join('outputs', 'titanic_model.pkl')\r\n",
        "joblib.dump(value=model, filename=model_file)\r\n",
        "\r\n",
        "\r\n",
        "# Register the model\r\n",
        "print('Registering model...')\r\n",
        "Model.register(workspace=run.experiment.workspace,\r\n",
        "               model_path = model_file,\r\n",
        "               model_name = 'titanic_model',\r\n",
        "               tags={'Training context':'Pipeline'},\r\n",
        "               properties={'AUC': np.float(auc), 'Accuracy': np.float(acc)})\r\n",
        "\r\n",
        "\r\n",
        "run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting titanic_pipeline/train_titanic.py\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "\r\n",
        "cluster_name = \"sweetdreams\"\r\n",
        "\r\n",
        "try:\r\n",
        "    # Check for existing compute target\r\n",
        "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\r\n",
        "    print('Found existing cluster, use it.')\r\n",
        "except ComputeTargetException:\r\n",
        "    # If it doesn't already exist, create it\r\n",
        "    try:\r\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\r\n",
        "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\r\n",
        "        pipeline_cluster.wait_for_completion(show_output=True)\r\n",
        "    except Exception as ex:\r\n",
        "        print(ex)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing cluster, use it.\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677382898195
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/experiment_env.yml\r\n",
        "name: experiment_env\r\n",
        "dependencies:\r\n",
        "- python=3.6.2\r\n",
        "- scikit-learn\r\n",
        "- ipykernel\r\n",
        "- matplotlib\r\n",
        "- pandas\r\n",
        "- pip\r\n",
        "- pip:\r\n",
        "  - azureml-defaults\r\n",
        "  - pyarrow"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting titanic_pipeline/experiment_env.yml\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\r\n",
        "from azureml.core.runconfig import RunConfiguration\r\n",
        "\r\n",
        "# Create a Python environment for the experiment (from a .yml file)\r\n",
        "experiment_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/experiment_env.yml\")\r\n",
        "\r\n",
        "# Register the environment \r\n",
        "experiment_env.register(workspace=ws)\r\n",
        "registered_env = Environment.get(ws, 'experiment_env')\r\n",
        "\r\n",
        "# Create a new runconfig object for the pipeline\r\n",
        "pipeline_run_config = RunConfiguration()\r\n",
        "\r\n",
        "# Use the compute you created above. \r\n",
        "pipeline_run_config.target = pipeline_cluster\r\n",
        "\r\n",
        "# Assign the environment to the run configuration\r\n",
        "pipeline_run_config.environment = registered_env\r\n",
        "\r\n",
        "print (\"Run configuration created.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Run configuration created.\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677382898715
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data import OutputFileDatasetConfig\r\n",
        "from azureml.pipeline.steps import PythonScriptStep\r\n",
        "\r\n",
        "\r\n",
        "# Get the training dataset\r\n",
        "titanic_ds = ws.datasets.get(\"titanic dataset\")\r\n",
        "\r\n",
        "# Create an OutputFileDatasetConfig (temporary Data Reference) for data passed from step 1 to step 2\r\n",
        "prepped_data = OutputFileDatasetConfig(\"prepped_data\")\r\n",
        "\r\n",
        "# Step 1, Run the data prep script\r\n",
        "prep_step = PythonScriptStep(name = \"Prepare Data\",\r\n",
        "                                source_directory = experiment_folder,\r\n",
        "                                script_name = \"prep_titanic.py\",\r\n",
        "                                arguments = ['--input-data', titanic_ds.as_named_input('raw_data'),\r\n",
        "                                             '--prepped-data', prepped_data],\r\n",
        "                                compute_target = pipeline_cluster,\r\n",
        "                                runconfig = pipeline_run_config,\r\n",
        "                                allow_reuse = True)\r\n",
        "\r\n",
        "# Step 2, run the training script\r\n",
        "train_step = PythonScriptStep(name = \"Train and Register Model\",\r\n",
        "                                source_directory = experiment_folder,\r\n",
        "                                script_name = \"train_titanic.py\",\r\n",
        "                                arguments = ['--training-data', prepped_data.as_input()],\r\n",
        "                                compute_target = pipeline_cluster,\r\n",
        "                                runconfig = pipeline_run_config,\r\n",
        "                                allow_reuse = True)\r\n",
        "\r\n",
        "print(\"Pipeline steps defined\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Pipeline steps defined\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677382899131
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "from azureml.core import Experiment\r\n",
        "from azureml.pipeline.core import Pipeline\r\n",
        "from azureml.widgets import RunDetails\r\n",
        "\r\n",
        "# Construct the pipeline\r\n",
        "pipeline_steps = [prep_step, train_step]\r\n",
        "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\r\n",
        "print(\"Pipeline is built.\")\r\n",
        "\r\n",
        "# Create an experiment and run the pipeline\r\n",
        "experiment = Experiment(workspace=ws, name = 'titanic-pipeline')\r\n",
        "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\r\n",
        "print(\"Pipeline submitted for execution.\")\r\n",
        "RunDetails(pipeline_run).show()\r\n",
        "pipeline_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Pipeline is built.\nCreated step Prepare Data [932d89eb][be8645cd-8cfd-4d67-b3a9-62678beab6d5], (This step will run and generate new outputs)\nCreated step Train and Register Model [419c466c][3e919d11-a94f-4d12-b081-634b28aac829], (This step will run and generate new outputs)\nSubmitted PipelineRun 46519ae6-2df9-4478-89bf-c01cda5c2aff\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/46519ae6-2df9-4478-89bf-c01cda5c2aff?wsid=/subscriptions/71fa0172-ce90-403c-94a9-14ce1e88f56a/resourcegroups/rg_eastus_44930_1_1677382226452/workspaces/testerinois&tid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3\nPipeline submitted for execution.\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', â€¦",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "27c5b5f04d66411092aaaa43e0b22d99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/46519ae6-2df9-4478-89bf-c01cda5c2aff?wsid=/subscriptions/71fa0172-ce90-403c-94a9-14ce1e88f56a/resourcegroups/rg_eastus_44930_1_1677382226452/workspaces/testerinois&tid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3\", \"run_id\": \"46519ae6-2df9-4478-89bf-c01cda5c2aff\", \"run_properties\": {\"run_id\": \"46519ae6-2df9-4478-89bf-c01cda5c2aff\", \"created_utc\": \"2023-02-26T03:41:43.66874Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\", \"azureml.continue_on_step_failure\": \"False\", \"azureml.continue_on_failed_optional_input\": \"True\", \"azureml.pipelineComponent\": \"pipelinerun\", \"azureml.pipelines.stages\": \"{\\\"Initialization\\\":null,\\\"Execution\\\":{\\\"StartTime\\\":\\\"2023-02-26T03:41:45.2309061+00:00\\\",\\\"EndTime\\\":\\\"2023-02-26T04:00:02.0594978+00:00\\\",\\\"Status\\\":\\\"Finished\\\"}}\"}, \"tags\": {}, \"end_time_utc\": \"2023-02-26T04:00:02.124482Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://testerinois6943754373.blob.core.windows.net/azureml/ExperimentRun/dcid.46519ae6-2df9-4478-89bf-c01cda5c2aff/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=JBLKpI048OaQ77ZXe59mXt9HNB64ZeeTEXCieFjn84k%3D&skoid=4b71d3f9-8a02-4b54-99c7-b88484da6ba1&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-26T03%3A31%3A45Z&ske=2023-02-27T11%3A41%3A45Z&sks=b&skv=2019-07-07&st=2023-02-26T04%3A15%3A17Z&se=2023-02-26T12%3A25%3A17Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://testerinois6943754373.blob.core.windows.net/azureml/ExperimentRun/dcid.46519ae6-2df9-4478-89bf-c01cda5c2aff/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=ebMli8J3N4QaY0MRkSD6DqJ9C52nYIhbNMD2B%2FLFrBo%3D&skoid=4b71d3f9-8a02-4b54-99c7-b88484da6ba1&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-26T03%3A31%3A45Z&ske=2023-02-27T11%3A41%3A45Z&sks=b&skv=2019-07-07&st=2023-02-26T04%3A15%3A17Z&se=2023-02-26T12%3A25%3A17Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://testerinois6943754373.blob.core.windows.net/azureml/ExperimentRun/dcid.46519ae6-2df9-4478-89bf-c01cda5c2aff/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=aoo8yffI%2Bct7shqPEd%2Ft%2BN8qXnbnMOIX56lGOO56TsQ%3D&skoid=4b71d3f9-8a02-4b54-99c7-b88484da6ba1&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-26T03%3A31%3A45Z&ske=2023-02-27T11%3A41%3A45Z&sks=b&skv=2019-07-07&st=2023-02-26T04%3A15%3A17Z&se=2023-02-26T12%3A25%3A17Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:18:18\", \"run_number\": \"1677382903\", \"run_queued_details\": {\"status\": \"Finished\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"28412720-e492-40ef-b6ab-757ce5323bcf\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"start_time\": \"2023-02-26T03:55:58.283069Z\", \"created_time\": \"2023-02-26T03:41:46.50784Z\", \"end_time\": \"2023-02-26T03:59:27.437994Z\", \"duration\": \"0:17:40\", \"run_number\": 1677382906, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2023-02-26T03:41:46.50784Z\", \"is_reused\": \"\"}, {\"run_id\": \"0d8f69ed-8051-43ee-b62f-d0e96c7b3d44\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"start_time\": \"2023-02-26T03:59:38.913273Z\", \"created_time\": \"2023-02-26T03:59:30.755575Z\", \"end_time\": \"2023-02-26T04:00:01.05428Z\", \"duration\": \"0:00:30\", \"run_number\": 1677383970, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2023-02-26T03:59:30.755575Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2023-02-26 03:41:45Z] Submitting 1 runs, first five are: 932d89eb:28412720-e492-40ef-b6ab-757ce5323bcf\\n[2023-02-26 03:59:28Z] Completing processing run id 28412720-e492-40ef-b6ab-757ce5323bcf.\\n[2023-02-26 03:59:28Z] Submitting 1 runs, first five are: 419c466c:0d8f69ed-8051-43ee-b62f-d0e96c7b3d44\\n[2023-02-26 04:00:01Z] Completing processing run id 0d8f69ed-8051-43ee-b62f-d0e96c7b3d44.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {\"821f1c54\": {\"node_id\": \"821f1c54\", \"name\": \"titanic dataset\"}}, \"module_nodes\": {\"932d89eb\": {\"node_id\": \"932d89eb\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"28412720-e492-40ef-b6ab-757ce5323bcf\"}, \"419c466c\": {\"node_id\": \"419c466c\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"0d8f69ed-8051-43ee-b62f-d0e96c7b3d44\"}}, \"edges\": [{\"source_node_id\": \"821f1c54\", \"source_node_name\": \"titanic dataset\", \"source_name\": \"data\", \"target_name\": \"raw_data\", \"dst_node_id\": \"932d89eb\", \"dst_node_name\": \"Prepare Data\"}, {\"source_node_id\": \"932d89eb\", \"source_node_name\": \"Prepare Data\", \"source_name\": \"prepped_data\", \"target_name\": \"input_c35d7190\", \"dst_node_id\": \"419c466c\", \"dst_node_name\": \"Train and Register Model\"}], \"child_runs\": [{\"run_id\": \"28412720-e492-40ef-b6ab-757ce5323bcf\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"start_time\": \"2023-02-26T03:55:58.283069Z\", \"created_time\": \"2023-02-26T03:41:46.50784Z\", \"end_time\": \"2023-02-26T03:59:27.437994Z\", \"duration\": \"0:17:40\", \"run_number\": 1677382906, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2023-02-26T03:41:46.50784Z\", \"is_reused\": \"\"}, {\"run_id\": \"0d8f69ed-8051-43ee-b62f-d0e96c7b3d44\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"start_time\": \"2023-02-26T03:59:38.913273Z\", \"created_time\": \"2023-02-26T03:59:30.755575Z\", \"end_time\": \"2023-02-26T04:00:01.05428Z\", \"duration\": \"0:00:30\", \"run_number\": 1677383970, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2023-02-26T03:59:30.755575Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.48.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "PipelineRunId: 46519ae6-2df9-4478-89bf-c01cda5c2aff\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/46519ae6-2df9-4478-89bf-c01cda5c2aff?wsid=/subscriptions/71fa0172-ce90-403c-94a9-14ce1e88f56a/resourcegroups/rg_eastus_44930_1_1677382226452/workspaces/testerinois&tid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3\nPipelineRun Status: Running\n\n\nStepRunId: 28412720-e492-40ef-b6ab-757ce5323bcf\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/28412720-e492-40ef-b6ab-757ce5323bcf?wsid=/subscriptions/71fa0172-ce90-403c-94a9-14ce1e88f56a/resourcegroups/rg_eastus_44930_1_1677382226452/workspaces/testerinois&tid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3\nStepRun( Prepare Data ) Status: Running\n\nStreaming azureml-logs/20_image_build_log.txt\n=============================================\n2023/02/26 03:42:03 Downloading source code...\n2023/02/26 03:42:04 Finished downloading source code\n2023/02/26 03:42:05 Creating Docker network: acb_default_network, driver: 'bridge'\n2023/02/26 03:42:05 Successfully set up Docker network: acb_default_network\n2023/02/26 03:42:05 Setting up Docker configuration...\n2023/02/26 03:42:06 Successfully set up Docker configuration\n2023/02/26 03:42:06 Logging in to registry: a9df04dede0641e0b00838f7861296d3.azurecr.io\n2023/02/26 03:42:07 Successfully logged into a9df04dede0641e0b00838f7861296d3.azurecr.io\n2023/02/26 03:42:07 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n2023/02/26 03:42:07 Scanning for dependencies...\n2023/02/26 03:42:07 Successfully scanned dependencies\n2023/02/26 03:42:07 Launching container with name: acb_step_0\nSending build context to Docker daemon  71.68kB\n\nStep 1/21 : FROM mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221101.v1@sha256:4505a963b2d34a42b5eaef48b8142ca98123d05d3a95eee3fe57551570a70e3b\nmcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221101.v1@sha256:4505a963b2d34a42b5eaef48b8142ca98123d05d3a95eee3fe57551570a70e3b: Pulling from azureml/openmpi4.1.0-ubuntu20.04\nd7bfe07ed847: Pulling fs layer\nd1327a17a430: Pulling fs layer\n69a9739a8058: Pulling fs layer\n1551e9d33102: Pulling fs layer\n726392826fd2: Pulling fs layer\n6ed0c5c30145: Pulling fs layer\nea261e5684f6: Pulling fs layer\n21207d3ea9d3: Pulling fs layer\nc9a742e394f6: Pulling fs layer\nb0c9de384791: Pulling fs layer\n1551e9d33102: Waiting\n726392826fd2: Waiting\n6ed0c5c30145: Waiting\nea261e5684f6: Waiting\n21207d3ea9d3: Waiting\nc9a742e394f6: Waiting\nb0c9de384791: Waiting\nd7bfe07ed847: Verifying Checksum\nd7bfe07ed847: Download complete\n1551e9d33102: Verifying Checksum\n1551e9d33102: Download complete\n726392826fd2: Verifying Checksum\n726392826fd2: Download complete\n69a9739a8058: Verifying Checksum\n69a9739a8058: Download complete\nea261e5684f6: Verifying Checksum\nea261e5684f6: Download complete\n21207d3ea9d3: Verifying Checksum\n21207d3ea9d3: Download complete\n6ed0c5c30145: Verifying Checksum\n6ed0c5c30145: Download complete\nc9a742e394f6: Verifying Checksum\nc9a742e394f6: Download complete\nb0c9de384791: Verifying Checksum\nb0c9de384791: Download complete\nd7bfe07ed847: Pull complete\nd1327a17a430: Verifying Checksum\nd1327a17a430: Download complete\nd1327a17a430: Pull complete\n69a9739a8058: Pull complete\n1551e9d33102: Pull complete\n726392826fd2: Pull complete\n6ed0c5c30145: Pull complete\nea261e5684f6: Pull complete\n21207d3ea9d3: Pull complete\nc9a742e394f6: Pull complete\nb0c9de384791: Pull complete\nDigest: sha256:4505a963b2d34a42b5eaef48b8142ca98123d05d3a95eee3fe57551570a70e3b\nStatus: Downloaded newer image for mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221101.v1@sha256:4505a963b2d34a42b5eaef48b8142ca98123d05d3a95eee3fe57551570a70e3b\n ---> b6fd6a8d28e9\nStep 2/21 : USER root\n ---> Running in af099a1a705d\nRemoving intermediate container af099a1a705d\n ---> ac9ae1ad76d6\nStep 3/21 : RUN mkdir -p $HOME/.cache\n ---> Running in 81bd616c62a4\nRemoving intermediate container 81bd616c62a4\n ---> e8ca74cd8ac3\nStep 4/21 : WORKDIR /\n ---> Running in 95ff7ad31d1e\nRemoving intermediate container 95ff7ad31d1e\n ---> 9a0575823558\nStep 5/21 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n ---> 448ead1c2740\nStep 6/21 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n ---> Running in 25a91671ff2e\nRemoving intermediate container 25a91671ff2e\n ---> 9d22e3baf486\nStep 7/21 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n ---> 221480873c0a\nStep 8/21 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n ---> Running in 34904f601d73\nCollecting package metadata (repodata.json): ...working... done\nSolving environment: ...working... done\n\nDownloading and Extracting Packages\n\ngstreamer-1.14.0     | 3.1 MB    |            |   0% \ngstreamer-1.14.0     | 3.1 MB    |            |   0% \ngstreamer-1.14.0     | 3.1 MB    | ########## | 100% \ngstreamer-1.14.0     | 3.1 MB    | ########## | 100% \n\nzstd-1.5.2           | 488 KB    |            |   0% \nzstd-1.5.2           | 488 KB    | ########## | 100% \n\nlibgomp-11.2.0       | 474 KB    |            |   0% \nlibgomp-11.2.0       | 474 KB    | ########## | 100% \n\nlibxml2-2.9.14       | 718 KB    |            |   0% \nlibxml2-2.9.14       | 718 KB    | ########## | 100% \n\npython-3.6.2         | 23.6 MB   |            |   0% \npython-3.6.2         | 23.6 MB   | ####9      |  49% \npython-3.6.2         | 23.6 MB   | ########## | 100% \npython-3.6.2         | 23.6 MB   | ########## | 100% \n\nlibtiff-4.5.0        | 524 KB    |            |   0% \nlibtiff-4.5.0        | 524 KB    | ########## | 100% \n\nmkl-2020.2           | 138.3 MB  |            |   0% \nmkl-2020.2           | 138.3 MB  | 6          |   6% \nmkl-2020.2           | 138.3 MB  | #5         |  15% \nmkl-2020.2           | 138.3 MB  | ##2        |  23% \nmkl-2020.2           | 138.3 MB  | ###1       |  32% \nmkl-2020.2           | 138.3 MB  | ###9       |  40% \nmkl-2020.2           | 138.3 MB  | ####8      |  48% \nmkl-2020.2           | 138.3 MB  | #####6     |  57% \nmkl-2020.2           | 138.3 MB  | ######6    |  67% \nmkl-2020.2           | 138.3 MB  | #######5   |  76% \nmkl-2020.2           | 138.3 MB  | ########4  |  84% \nmkl-2020.2           | 138.3 MB  | #########3 |  93% \nmkl-2020.2           | 138.3 MB  | ########## | 100% \n\nlibffi-3.2.1         | 48 KB     |            |   0% \nlibffi-3.2.1         | 48 KB     | ########## | 100% \n\npillow-8.3.1         | 637 KB    |            |   0% \npillow-8.3.1         | 637 KB    | ########## | 100% \n\npickleshare-0.7.5    | 13 KB     |            |   0% \npickleshare-0.7.5    | 13 KB     | ########## | 100% \n\npygments-2.11.2      | 759 KB    |            |   0% \npygments-2.11.2      | 759 KB    | ########## | 100% \n\ntraitlets-4.3.3      | 138 KB    |            |   0% \ntraitlets-4.3.3      | 138 KB    | ########## | 100% \n\n_libgcc_mutex-0.1    | 3 KB      |            |   0% \n_libgcc_mutex-0.1    | 3 KB      | ########## | 100% \n\ntk-8.6.12            | 3.0 MB    |            |   0% \ntk-8.6.12            | 3.0 MB    | ########## | 100% \ntk-8.6.12            | 3.0 MB    | ########## | 100% \n\npytz-2021.3          | 171 KB    |            |   0% \npytz-2021.3          | 171 KB    | ########## | 100% \n\ncycler-0.11.0        | 12 KB     |            |   0% \ncycler-0.11.0        | 12 KB     | ########## | 100% \n\nglib-2.63.1          | 2.9 MB    |            |   0% \nglib-2.63.1          | 2.9 MB    | ########## | 100% \nglib-2.63.1          | 2.9 MB    | ########## | 100% \n\nopenjpeg-2.4.0       | 331 KB    |            |   0% \nopenjpeg-2.4.0       | 331 KB    | ########## | 100% \n\n_openmp_mutex-5.1    | 21 KB     |            |   0% \n_openmp_mutex-5.1    | 21 KB     | ########## | 100% \n\nblas-1.0             | 6 KB      |            |   0% \nblas-1.0             | 6 KB      | ########## | 100% \n\nipython_genutils-0.2 | 27 KB     |            |   0% \nipython_genutils-0.2 | 27 KB     | ########## | 100% \n\nsetuptools-58.0.4    | 788 KB    |            |   0% \nsetuptools-58.0.4    | 788 KB    | ########## | 100% \n\njpeg-9e              | 240 KB    |            |   0% \njpeg-9e              | 240 KB    | ########## | 100% \n\nthreadpoolctl-2.2.0  | 16 KB     |            |   0% \nthreadpoolctl-2.2.0  | 16 KB     | ########## | 100% \n\nsix-1.16.0           | 18 KB     |            |   0% \nsix-1.16.0           | 18 KB     | ########## | 100% \n\njoblib-1.0.1         | 208 KB    |            |   0% \njoblib-1.0.1         | 208 KB    | ########## | 100% \n\nptyprocess-0.7.0     | 17 KB     |            |   0% \nptyprocess-0.7.0     | 17 KB     | ########## | 100% \n\nzeromq-4.3.4         | 331 KB    |            |   0% \nzeromq-4.3.4         | 331 KB    | ########## | 100% \n\nopenssl-1.0.2u       | 2.2 MB    |            |   0% \nopenssl-1.0.2u       | 2.2 MB    | ########## | 100% \n\npandas-1.1.5         | 8.2 MB    |            |   0% \npandas-1.1.5         | 8.2 MB    | ########## | 100% \npandas-1.1.5         | 8.2 MB    | ########## | 100% \n\nlibuuid-1.41.5       | 27 KB     |            |   0% \nlibuuid-1.41.5       | 27 KB     | ########## | 100% \n\nreadline-7.0         | 848 KB    |            |   0% \nreadline-7.0         | 848 KB    | ########## | 100% \n\npython-dateutil-2.8. | 233 KB    |            |   0% \npython-dateutil-2.8. | 233 KB    | ########## | 100% \n\nparso-0.8.3          | 70 KB     |            |   0% \nparso-0.8.3          | 70 KB     | ########## | 100% \n\nmkl_random-1.1.1     | 327 KB    |            |   0% \nmkl_random-1.1.1     | 327 KB    | ########## | 100% \n\nscikit-learn-0.24.2  | 5.2 MB    |            |   0% \nscikit-learn-0.24.2  | 5.2 MB    | ########## | 100% \nscikit-learn-0.24.2  | 5.2 MB    | ########## | 100% \n\nsqlite-3.23.1        | 808 KB    |            |   0% \nsqlite-3.23.1        | 808 KB    | ########## | 100% \n\nlibsodium-1.0.18     | 244 KB    |            |   0% \nlibsodium-1.0.18     | 244 KB    | ########## | 100% \n\nintel-openmp-2022.1. | 4.5 MB    |            |   0% \nintel-openmp-2022.1. | 4.5 MB    | ########## | 100% \nintel-openmp-2022.1. | 4.5 MB    | ########## | 100% \n\nlibpng-1.6.37        | 278 KB    |            |   0% \nlibpng-1.6.37        | 278 KB    | ########## | 100% \n\npyqt-5.9.2           | 4.5 MB    |            |   0% \npyqt-5.9.2           | 4.5 MB    | ########## | 100% \npyqt-5.9.2           | 4.5 MB    | ########## | 100% \n\npip-21.2.2           | 1.8 MB    |            |   0% \npip-21.2.2           | 1.8 MB    | ########## | 100% \npip-21.2.2           | 1.8 MB    | ########## | 100% \n\nlibgfortran-ng-7.5.0 | 22 KB     |            |   0% \nlibgfortran-ng-7.5.0 | 22 KB     | ########## | 100% \n\nlz4-c-1.9.4          | 154 KB    |            |   0% \nlz4-c-1.9.4          | 154 KB    | ########## | 100% \n\nicu-58.2             | 10.5 MB   |            |   0% \nicu-58.2             | 10.5 MB   | ########## | 100% \nicu-58.2             | 10.5 MB   | ########## | 100% \n\nlerc-3.0             | 196 KB    |            |   0% \nlerc-3.0             | 196 KB    | ########## | 100% \n\nnumpy-base-1.19.2    | 4.1 MB    |            |   0% \nnumpy-base-1.19.2    | 4.1 MB    | ########## | 100% \nnumpy-base-1.19.2    | 4.1 MB    | ########## | 100% \n\njedi-0.17.0          | 780 KB    |            |   0% \njedi-0.17.0          | 780 KB    | ########## | 100% \njedi-0.17.0          | 780 KB    | ########## | 100% \n\ngst-plugins-base-1.1 | 4.8 MB    |            |   0% \ngst-plugins-base-1.1 | 4.8 MB    | ########## | 100% \ngst-plugins-base-1.1 | 4.8 MB    | ########## | 100% \n\nwheel-0.37.1         | 33 KB     |            |   0% \nwheel-0.37.1         | 33 KB     | ########## | 100% \n\nca-certificates-2023 | 120 KB    |            |   0% \nca-certificates-2023 | 120 KB    | ########## | 100% \n\nlibxcb-1.15          | 505 KB    |            |   0% \nlibxcb-1.15          | 505 KB    | ########## | 100% \n\nexpat-2.4.9          | 156 KB    |            |   0% \nexpat-2.4.9          | 156 KB    | ########## | 100% \n\nncurses-6.0          | 781 KB    |            |   0% \nncurses-6.0          | 781 KB    | ########## | 100% \nncurses-6.0          | 781 KB    | ########## | 100% \n\nmkl-service-2.3.0    | 52 KB     |            |   0% \nmkl-service-2.3.0    | 52 KB     | ########## | 100% \n\nkiwisolver-1.3.1     | 86 KB     |            |   0% \nkiwisolver-1.3.1     | 86 KB     | ########## | 100% \n\nscipy-1.5.2          | 14.4 MB   |            |   0% \nscipy-1.5.2          | 14.4 MB   | #######9   |  80% \nscipy-1.5.2          | 14.4 MB   | ########## | 100% \n\nnumpy-1.19.2         | 22 KB     |            |   0% \nnumpy-1.19.2         | 22 KB     | ########## | 100% \n\ndbus-1.13.18         | 504 KB    |            |   0% \ndbus-1.13.18         | 504 KB    | ########## | 100% \n\nlibstdcxx-ng-11.2.0  | 4.7 MB    |            |   0% \nlibstdcxx-ng-11.2.0  | 4.7 MB    | ########## | 100% \nlibstdcxx-ng-11.2.0  | 4.7 MB    | ########## | 100% \n\nentrypoints-0.3      | 12 KB     |            |   0% \nentrypoints-0.3      | 12 KB     | ########## | 100% \n\npyzmq-22.2.1         | 454 KB    |            |   0% \npyzmq-22.2.1         | 454 KB    | ########## | 100% \n\nlibgcc-ng-11.2.0     | 5.3 MB    |            |   0% \nlibgcc-ng-11.2.0     | 5.3 MB    | ########## | 100% \nlibgcc-ng-11.2.0     | 5.3 MB    | ########## | 100% \n\nlibgfortran4-7.5.0   | 995 KB    |            |   0% \nlibgfortran4-7.5.0   | 995 KB    | ########## | 100% \n\nlibedit-3.1          | 151 KB    |            |   0% \nlibedit-3.1          | 151 KB    | ########## | 100% \n\njupyter_client-7.1.2 | 93 KB     |            |   0% \njupyter_client-7.1.2 | 93 KB     | ########## | 100% \n\nxz-5.2.10            | 429 KB    |            |   0% \nxz-5.2.10            | 429 KB    | ########## | 100% \n\npcre-8.45            | 207 KB    |            |   0% \npcre-8.45            | 207 KB    | ########## | 100% \n\nwcwidth-0.2.5        | 26 KB     |            |   0% \nwcwidth-0.2.5        | 26 KB     | ########## | 100% \n\nipython-7.16.1       | 999 KB    |            |   0% \nipython-7.16.1       | 999 KB    | ########## | 100% \nipython-7.16.1       | 999 KB    | ########## | 100% \n\nqt-5.9.6             | 67.3 MB   |            |   0% \nqt-5.9.6             | 67.3 MB   | #1         |  12% \nqt-5.9.6             | 67.3 MB   | ##7        |  27% \nqt-5.9.6             | 67.3 MB   | ####3      |  43% \nqt-5.9.6             | 67.3 MB   | #####8     |  59% \nqt-5.9.6             | 67.3 MB   | #######4   |  74% \nqt-5.9.6             | 67.3 MB   | #########2 |  93% \nqt-5.9.6             | 67.3 MB   | ########## | 100% \n\njupyter_core-4.8.1   | 74 KB     |            |   0% \njupyter_core-4.8.1   | 74 KB     | ########## | 100% \n\nprompt-toolkit-3.0.2 | 259 KB    |            |   0% \nprompt-toolkit-3.0.2 | 259 KB    | ########## | 100% \n\nfontconfig-2.14.1    | 281 KB    |            |   0% \nfontconfig-2.14.1    | 281 KB    | ########## | 100% \n\npyparsing-3.0.4      | 81 KB     |            |   0% \npyparsing-3.0.4      | 81 KB     | ########## | 100% \n\ncertifi-2021.5.30    | 139 KB    |            |   0% \ncertifi-2021.5.30    | 139 KB    | ########## | 100% \n\npexpect-4.8.0        | 53 KB     |            |   0% \npexpect-4.8.0        | 53 KB     | ########## | 100% \n\nnest-asyncio-1.5.1   | 10 KB     |            |   0% \nnest-asyncio-1.5.1   | 10 KB     | ########## | 100% \n\nsip-4.19.8           | 274 KB    |            |   0% \nsip-4.19.8           | 274 KB    | ########## | 100% \n\nlibwebp-base-1.2.4   | 376 KB    |            |   0% \nlibwebp-base-1.2.4   | 376 KB    | ########## | 100% \n\nlibdeflate-1.8       | 51 KB     |            |   0% \nlibdeflate-1.8       | 51 KB     | ########## | 100% \n\nmkl_fft-1.3.0        | 170 KB    |            |   0% \nmkl_fft-1.3.0        | 170 KB    | ########## | 100% \n\nolefile-0.46         | 48 KB     |            |   0% \nolefile-0.46         | 48 KB     | ########## | 100% \n\ndecorator-5.1.1      | 12 KB     |            |   0% \ndecorator-5.1.1      | 12 KB     | ########## | 100% \n\nfreetype-2.12.1      | 626 KB    |            |   0% \nfreetype-2.12.1      | 626 KB    | ########## | 100% \n\nzlib-1.2.13          | 103 KB    |            |   0% \nzlib-1.2.13          | 103 KB    | ########## | 100% \n\nmatplotlib-3.3.4     | 26 KB     |            |   0% \nmatplotlib-3.3.4     | 26 KB     | ########## | 100% \n\ntornado-6.1          | 581 KB    |            |   0% \ntornado-6.1          | 581 KB    | ########## | 100% \n\nbackcall-0.2.0       | 13 KB     |            |   0% \nbackcall-0.2.0       | 13 KB     | ########## | 100% \n\nipykernel-5.3.4      | 181 KB    |            |   0% \nipykernel-5.3.4      | 181 KB    | ########## | 100% \n\nmatplotlib-base-3.3. | 5.1 MB    |            |   0% \nmatplotlib-base-3.3. | 5.1 MB    | ########## | 100% \nmatplotlib-base-3.3. | 5.1 MB    | ########## | 100% \n\nlcms2-2.12           | 312 KB    |            |   0% \nlcms2-2.12           | 312 KB    | ########## | 100% \nPreparing transaction: ...working... done\nVerifying transaction: ...working... done\nExecuting transaction: ...working... \n\n    Installed package of scikit-learn can be accelerated using scikit-learn-intelex.\n    More details are available here: https://intel.github.io/scikit-learn-intelex\n\n    For example:\n\n        $ conda install scikit-learn-intelex\n        $ python -m sklearnex my_application.py\n\n    \n\ndone\nInstalling pip dependencies: ...working... \nRan pip subprocess with arguments:\n['/azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.8_70qhhu.requirements.txt']\nPip subprocess output:\nCollecting azureml-defaults\n  Downloading azureml_defaults-1.49.0-py3-none-any.whl (2.0 kB)\nCollecting pyarrow\n  Downloading pyarrow-6.0.1-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.6 MB)\nCollecting azureml-defaults\n  Downloading azureml_defaults-1.48.0-py3-none-any.whl (2.0 kB)\nCollecting azureml-dataset-runtime[fuse]~=1.48.0\n  Downloading azureml_dataset_runtime-1.48.0-py3-none-any.whl (2.2 kB)\nCollecting azureml-inference-server-http~=0.7.2\n  Downloading azureml_inference_server_http-0.7.7-py3-none-any.whl (56 kB)\nCollecting azureml-defaults\n  Downloading azureml_defaults-1.47.0-py3-none-any.whl (2.0 kB)\nCollecting json-logging-py==0.2\n  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\nCollecting azureml-core~=1.47.0\n  Downloading azureml_core-1.47.0-py3-none-any.whl (3.1 MB)\nCollecting configparser==3.7.4\n  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\nCollecting azureml-dataset-runtime[fuse]~=1.47.0\n  Downloading azureml_dataset_runtime-1.47.0-py3-none-any.whl (2.2 kB)\nRequirement already satisfied: numpy>=1.16.6 in /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/lib/python3.6/site-packages (from pyarrow->-r /azureml-environment-setup/condaenv.8_70qhhu.requirements.txt (line 2)) (1.19.2)\nCollecting backports.tempfile\n  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\nCollecting contextlib2<22.0.0\n  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\nCollecting msal<2.0.0,>=1.15.0\n  Downloading msal-1.21.0-py2.py3-none-any.whl (89 kB)\nCollecting azure-mgmt-storage<21.0.0,>=16.0.0\n  Downloading azure_mgmt_storage-20.0.0-py3-none-any.whl (2.0 MB)\nCollecting msrest<=0.7.1,>=0.5.1\n  Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\nCollecting azure-mgmt-authorization<3,>=0.40.0\n  Downloading azure_mgmt_authorization-2.0.0-py2.py3-none-any.whl (465 kB)\nCollecting adal<=1.2.7,>=1.2.0\n  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\nCollecting azure-mgmt-keyvault<11.0.0,>=0.40.0\n  Downloading azure_mgmt_keyvault-10.0.0-py3-none-any.whl (489 kB)\nCollecting requests[socks]<3.0.0,>=2.19.1\n  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\nCollecting pathspec<1.0.0\n  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\nCollecting knack~=0.10.0\n  Downloading knack-0.10.1-py3-none-any.whl (61 kB)\nCollecting argcomplete<3\n  Downloading argcomplete-2.0.0-py2.py3-none-any.whl (37 kB)\nCollecting ndg-httpsclient<=0.5.1\n  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\nCollecting PyJWT<3.0.0\n  Downloading PyJWT-2.4.0-py3-none-any.whl (18 kB)\nCollecting pyopenssl<23.0.0\n  Downloading pyOpenSSL-22.1.0-py3-none-any.whl (57 kB)\nCollecting paramiko<3.0.0,>=2.0.8\n  Downloading paramiko-2.12.0-py2.py3-none-any.whl (213 kB)\nCollecting azure-mgmt-resource<22.0.0,>=15.0.0\n  Downloading azure_mgmt_resource-21.1.0-py3-none-any.whl (1.8 MB)\nCollecting urllib3<2.0.0,>=1.23\n  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\nCollecting docker<7.0.0\n  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\nCollecting packaging<22.0,>=20.0\n  Downloading packaging-21.3-py3-none-any.whl (40 kB)\nCollecting jmespath<2.0.0\n  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\nCollecting azure-common<2.0.0,>=1.1.12\n  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\nRequirement already satisfied: pytz in /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/lib/python3.6/site-packages (from azureml-core~=1.47.0->azureml-defaults->-r /azureml-environment-setup/condaenv.8_70qhhu.requirements.txt (line 1)) (2021.3)\nCollecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<41\n  Downloading cryptography-39.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (4.2 MB)\nCollecting pkginfo\n  Downloading pkginfo-1.9.6-py3-none-any.whl (30 kB)\nCollecting SecretStorage<4.0.0\n  Downloading SecretStorage-3.3.3-py3-none-any.whl (15 kB)\nCollecting jsonpickle<3.0.0\n  Downloading jsonpickle-2.2.0-py2.py3-none-any.whl (39 kB)\nCollecting msrestazure<=0.6.4,>=0.4.33\n  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\nCollecting msal-extensions<=1.0.0,>=0.3.0\n  Downloading msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB)\nCollecting azure-core<2.0.0\n  Downloading azure_core-1.24.2-py3-none-any.whl (178 kB)\nCollecting azure-graphrbac<1.0.0,>=0.40.0\n  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.7.3 in /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/lib/python3.6/site-packages (from azureml-core~=1.47.0->azureml-defaults->-r /azureml-environment-setup/condaenv.8_70qhhu.requirements.txt (line 1)) (2.8.2)\nCollecting humanfriendly<11.0,>=4.7\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\nCollecting azure-mgmt-containerregistry<11,>=8.2.0\n  Downloading azure_mgmt_containerregistry-10.0.0-py3-none-any.whl (1.2 MB)\nCollecting importlib-metadata<5,>=0.23\n  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\nCollecting typing-extensions>=4.0.1\n  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\nRequirement already satisfied: six>=1.11.0 in /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/lib/python3.6/site-packages (from azure-core<2.0.0->azureml-core~=1.47.0->azureml-defaults->-r /azureml-environment-setup/condaenv.8_70qhhu.requirements.txt (line 1)) (1.16.0)\nCollecting azure-mgmt-core<2.0.0,>=1.2.0\n  Downloading azure_mgmt_core-1.3.2-py3-none-any.whl (26 kB)\nCollecting azureml-dataprep<4.6.0a,>=4.5.0a\n  Downloading azureml_dataprep-4.5.7-py3-none-any.whl (43.4 MB)\nCollecting fusepy<4.0.0,>=3.0.1\n  Downloading fusepy-3.0.1.tar.gz (11 kB)\nCollecting azureml-dataprep-rslex~=2.11.0dev0\n  Downloading azureml_dataprep_rslex-2.11.4-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.3 MB)\nCollecting azureml-dataprep-native<39.0.0,>=38.0.0\n  Downloading azureml_dataprep_native-38.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\nCollecting cloudpickle<3.0.0,>=1.1.0\n  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\nCollecting azure-identity==1.7.0\n  Downloading azure_identity-1.7.0-py2.py3-none-any.whl (129 kB)\nCollecting jsonschema\n  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\nCollecting pyyaml<7.0.0,>=5.1.0\n  Downloading PyYAML-6.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (603 kB)\nCollecting dotnetcore2<4.0.0,>=3.0.0\n  Downloading dotnetcore2-3.1.23-py3-none-manylinux1_x86_64.whl (31.1 MB)\nCollecting msal-extensions<=1.0.0,>=0.3.0\n  Downloading msal_extensions-0.3.1-py2.py3-none-any.whl (18 kB)\nCollecting gunicorn==20.1.0\n  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\nCollecting opencensus-ext-azure~=1.1.0\n  Downloading opencensus_ext_azure-1.1.8-py2.py3-none-any.whl (42 kB)\nCollecting flask-cors~=3.0.1\n  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\nCollecting inference-schema~=1.4.0\n  Downloading inference_schema-1.4.2.1-py3-none-any.whl (21 kB)\nRequirement already satisfied: setuptools>=3.0 in /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/lib/python3.6/site-packages (from gunicorn==20.1.0->azureml-inference-server-http~=0.7.2->azureml-defaults->-r /azureml-environment-setup/condaenv.8_70qhhu.requirements.txt (line 1)) (58.0.4)\nCollecting cffi>=1.12\n  Downloading cffi-1.15.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (402 kB)\nCollecting pycparser\n  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\nCollecting websocket-client>=0.32.0\n  Downloading websocket_client-1.3.1-py3-none-any.whl (54 kB)\nCollecting distro>=1.2.0\n  Downloading distro-1.8.0-py3-none-any.whl (20 kB)\nCollecting Flask>=0.9\n  Downloading Flask-2.0.3-py3-none-any.whl (95 kB)\nCollecting Werkzeug>=2.0\n  Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\nCollecting click>=7.1.2\n  Downloading click-8.0.4-py3-none-any.whl (97 kB)\nCollecting itsdangerous>=2.0\n  Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)\nCollecting Jinja2>=3.0\n  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\nCollecting zipp>=0.5\n  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\nCollecting wrapt<=1.12.1,>=1.11.1\n  Downloading wrapt-1.12.1.tar.gz (27 kB)\nCollecting MarkupSafe>=2.0\n  Downloading MarkupSafe-2.0.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (30 kB)\nCollecting tabulate\n  Downloading tabulate-0.8.10-py3-none-any.whl (29 kB)\nRequirement already satisfied: pygments in /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/lib/python3.6/site-packages (from knack~=0.10.0->azureml-core~=1.47.0->azureml-defaults->-r /azureml-environment-setup/condaenv.8_70qhhu.requirements.txt (line 1)) (2.11.2)\nCollecting portalocker<3,>=1.0\n  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\nCollecting requests-oauthlib>=0.5.0\n  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\nRequirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/lib/python3.6/site-packages (from msrest<=0.7.1,>=0.5.1->azureml-core~=1.47.0->azureml-defaults->-r /azureml-environment-setup/condaenv.8_70qhhu.requirements.txt (line 1)) (2021.5.30)\nCollecting isodate>=0.6.0\n  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\nCollecting pyasn1>=0.1.1\n  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\nCollecting opencensus<1.0.0,>=0.11.1\n  Downloading opencensus-0.11.1-py2.py3-none-any.whl (128 kB)\nCollecting psutil>=5.6.3\n  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\nCollecting google-api-core<3.0.0,>=1.0.0\n  Downloading google_api_core-2.8.2-py3-none-any.whl (114 kB)\nCollecting opencensus-context>=0.1.3\n  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\nCollecting google-auth<3.0dev,>=1.25.0\n  Downloading google_auth-2.16.1-py2.py3-none-any.whl (177 kB)\nCollecting protobuf<5.0.0dev,>=3.15.0\n  Downloading protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\nCollecting googleapis-common-protos<2.0dev,>=1.56.2\n  Downloading googleapis_common_protos-1.56.3-py2.py3-none-any.whl (211 kB)\nCollecting rsa<5,>=3.1.4\n  Downloading rsa-4.9-py3-none-any.whl (34 kB)\nCollecting pyasn1-modules>=0.2.1\n  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\nCollecting cachetools<6.0,>=2.0.0\n  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\nCollecting contextvars\n  Downloading contextvars-2.4.tar.gz (9.6 kB)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/lib/python3.6/site-packages (from packaging<22.0,>=20.0->azureml-core~=1.47.0->azureml-defaults->-r /azureml-environment-setup/condaenv.8_70qhhu.requirements.txt (line 1)) (3.0.4)\nCollecting bcrypt>=3.1.3\n  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (593 kB)\nCollecting pynacl>=1.0.1\n  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\nCollecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<41\n  Downloading cryptography-38.0.4-cp36-abi3-manylinux_2_28_x86_64.whl (4.2 MB)\nCollecting charset-normalizer~=2.0.0\n  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\nCollecting idna<4,>=2.5\n  Downloading idna-3.4-py3-none-any.whl (61 kB)\nCollecting oauthlib>=3.0.0\n  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\nCollecting PySocks!=1.5.7,>=1.5.6\n  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\nCollecting jeepney>=0.6\n  Downloading jeepney-0.7.1-py3-none-any.whl (54 kB)\nCollecting dataclasses\n  Downloading dataclasses-0.8-py3-none-any.whl (19 kB)\nCollecting backports.weakref\n  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\nCollecting immutables>=0.9\n  Downloading immutables-0.19-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (116 kB)\nCollecting pyrsistent>=0.14.0\n  Downloading pyrsistent-0.18.0-cp36-cp36m-manylinux1_x86_64.whl (117 kB)\nCollecting attrs>=17.4.0\n  Downloading attrs-22.2.0-py3-none-any.whl (60 kB)\nBuilding wheels for collected packages: json-logging-py, fusepy, wrapt, contextvars\n  Building wheel for json-logging-py (setup.py): started\n  Building wheel for json-logging-py (setup.py): finished with status 'done'\n  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3924 sha256=3a3a1741986884c1e5d8301397db4c7c8af064314dfabc4fc720cb300165c526\n  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\n  Building wheel for fusepy (setup.py): started\n  Building wheel for fusepy (setup.py): finished with status 'done'\n  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10503 sha256=14fc1a2339c447db4922ace8a9207cd3a43bcee6b1657159706a8cb06d218ede\n  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n  Building wheel for wrapt (setup.py): started\n  Building wheel for wrapt (setup.py): finished with status 'done'\n  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=76178 sha256=781f3ab112f4e6991955f8b38f3f2ad86e856aa21bb338cfb24d45f2b0d76035\n  Stored in directory: /root/.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\n  Building wheel for contextvars (setup.py): started\n  Building wheel for contextvars (setup.py): finished with status 'done'\n  Created wheel for contextvars: filename=contextvars-2.4-py3-none-any.whl size=7681 sha256=9548828eba9ebc21b7d6fef32bfeb251211030fb1070a5b0da7babe44d54b0da\n  Stored in directory: /root/.cache/pip/wheels/41/11/53/911724983aa48deb94792432e14e518447212dd6c5477d49d3\nSuccessfully built json-logging-py fusepy wrapt contextvars\nInstalling collected packages: pycparser, cffi, urllib3, PyJWT, idna, cryptography, charset-normalizer, typing-extensions, requests, pyasn1, zipp, rsa, pyasn1-modules, protobuf, portalocker, oauthlib, msal, immutables, cachetools, requests-oauthlib, pyrsistent, msal-extensions, MarkupSafe, isodate, importlib-metadata, googleapis-common-protos, google-auth, distro, dataclasses, contextvars, azure-core, attrs, Werkzeug, pyyaml, opencensus-context, msrest, jsonschema, Jinja2, itsdangerous, google-api-core, dotnetcore2, cloudpickle, click, azureml-dataprep-rslex, azureml-dataprep-native, azure-identity, adal, wrapt, websocket-client, tabulate, PySocks, pyopenssl, pynacl, pyarrow, psutil, opencensus, msrestazure, jmespath, jeepney, Flask, bcrypt, backports.weakref, azureml-dataprep, azure-mgmt-core, azure-common, argcomplete, SecretStorage, pkginfo, pathspec, paramiko, packaging, opencensus-ext-azure, ndg-httpsclient, knack, jsonpickle, inference-schema, humanfriendly, gunicorn, fusepy, flask-cors, docker, contextlib2, backports.tempfile, azureml-dataset-runtime, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, azure-graphrbac, json-logging-py, configparser, azureml-inference-server-http, azureml-core, azureml-defaults\nSuccessfully installed Flask-2.0.3 Jinja2-3.0.3 MarkupSafe-2.0.1 PyJWT-2.4.0 PySocks-1.7.1 SecretStorage-3.3.3 Werkzeug-2.0.3 adal-1.2.7 argcomplete-2.0.0 attrs-22.2.0 azure-common-1.1.28 azure-core-1.24.2 azure-graphrbac-0.61.1 azure-identity-1.7.0 azure-mgmt-authorization-2.0.0 azure-mgmt-containerregistry-10.0.0 azure-mgmt-core-1.3.2 azure-mgmt-keyvault-10.0.0 azure-mgmt-resource-21.1.0 azure-mgmt-storage-20.0.0 azureml-core-1.47.0 azureml-dataprep-4.5.7 azureml-dataprep-native-38.0.0 azureml-dataprep-rslex-2.11.4 azureml-dataset-runtime-1.47.0 azureml-defaults-1.47.0 azureml-inference-server-http-0.7.7 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-4.0.1 cachetools-4.2.4 cffi-1.15.1 charset-normalizer-2.0.12 click-8.0.4 cloudpickle-2.2.1 configparser-3.7.4 contextlib2-21.6.0 contextvars-2.4 cryptography-38.0.4 dataclasses-0.8 distro-1.8.0 docker-5.0.3 dotnetcore2-3.1.23 flask-cors-3.0.10 fusepy-3.0.1 google-api-core-2.8.2 google-auth-2.16.1 googleapis-common-protos-1.56.3 gunicorn-20.1.0 humanfriendly-10.0 idna-3.4 immutables-0.19 importlib-metadata-4.8.3 inference-schema-1.4.2.1 isodate-0.6.1 itsdangerous-2.0.1 jeepney-0.7.1 jmespath-0.10.0 json-logging-py-0.2 jsonpickle-2.2.0 jsonschema-3.2.0 knack-0.10.1 msal-1.21.0 msal-extensions-0.3.1 msrest-0.7.1 msrestazure-0.6.4 ndg-httpsclient-0.5.1 oauthlib-3.2.2 opencensus-0.11.1 opencensus-context-0.1.3 opencensus-ext-azure-1.1.8 packaging-21.3 paramiko-2.12.0 pathspec-0.9.0 pkginfo-1.9.6 portalocker-2.7.0 protobuf-3.19.6 psutil-5.9.4 pyarrow-6.0.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycparser-2.21 pynacl-1.5.0 pyopenssl-22.1.0 pyrsistent-0.18.0 pyyaml-6.0 requests-2.27.1 requests-oauthlib-1.3.1 rsa-4.9 tabulate-0.8.10 typing-extensions-4.1.1 urllib3-1.26.14 websocket-client-1.3.1 wrapt-1.12.1 zipp-3.6.0\n\u001b[91m\n\n==> WARNING: A newer version of conda exists. <==\n  current version: 4.12.0\n  latest version: 23.1.0\n\nPlease update conda by running\n\n    $ conda update -n base -c defaults conda\n\n\n\u001b[0m\ndone\n#\n# To activate this environment, use\n#\n#     $ conda activate /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b\n#\n# To deactivate an active environment, use\n#\n#     $ conda deactivate\n\nWARNING: /root/.conda/pkgs does not exist\n\nRemoving intermediate container 34904f601d73\n ---> 12dd16122cac\nStep 9/21 : ENV PATH /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/bin:$PATH\n ---> Running in f6c26813a0f8\nRemoving intermediate container f6c26813a0f8\n ---> ecd8a3028153\nStep 10/21 : COPY azureml-environment-setup/send_conda_dependencies.py azureml-environment-setup/send_conda_dependencies.py\n ---> f95c8de298d9\nStep 11/21 : RUN echo \"Copying environment context\"\n ---> Running in 843c893bf371\nCopying environment context\nRemoving intermediate container 843c893bf371\n ---> b83d2d890605\nStep 12/21 : COPY azureml-environment-setup/environment_context.json azureml-environment-setup/environment_context.json\n ---> ebd41ab5a00b\nStep 13/21 : RUN python /azureml-environment-setup/send_conda_dependencies.py -p /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b\n ---> Running in 240b6e6019ef\nReport materialized dependencies for the environment\nReading environment context\nExporting conda environment\nSending request with materialized conda environment details\nSuccessfully sent materialized environment details\nRemoving intermediate container 240b6e6019ef\n ---> ba4b23627e87\nStep 14/21 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b\n ---> Running in 043bfbbd8a81\nRemoving intermediate container 043bfbbd8a81\n ---> 32c21e6dd31b\nStep 15/21 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/lib:$LD_LIBRARY_PATH\n ---> Running in e0a953d69634\nRemoving intermediate container e0a953d69634\n ---> 7048f009d138\nStep 16/21 : ENV CONDA_DEFAULT_ENV=azureml_0c5a9aa2def4b3c2501c1f40287a356b CONDA_PREFIX=/azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b\n ---> Running in 7911589f2308\nRemoving intermediate container 7911589f2308\n ---> 0f0f44579393\nStep 17/21 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n ---> 43170d08f51d\nStep 18/21 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n ---> Running in 59f7ed59bf3a\nRemoving intermediate container 59f7ed59bf3a\n ---> 4ec92524465d\nStep 19/21 : RUN rm -rf azureml-environment-setup\n ---> Running in bce09b2ba17f\nRemoving intermediate container bce09b2ba17f\n ---> 8cbee91022e2\nStep 20/21 : ENV AZUREML_ENVIRONMENT_IMAGE True\n ---> Running in 92d6b41b5896\nRemoving intermediate container 92d6b41b5896\n ---> c788d1910773\nStep 21/21 : CMD [\"bash\"]\n ---> Running in 0ac38828755a\nRemoving intermediate container 0ac38828755a\n ---> f68495f88ce1\nSuccessfully built f68495f88ce1\nSuccessfully tagged a9df04dede0641e0b00838f7861296d3.azurecr.io/azureml/azureml_eb4ae1f22a6b9a15bc42fb135660daf8:latest\nSuccessfully tagged a9df04dede0641e0b00838f7861296d3.azurecr.io/azureml/azureml_eb4ae1f22a6b9a15bc42fb135660daf8:1\n2023/02/26 03:44:45 Successfully executed container: acb_step_0\n2023/02/26 03:44:45 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n2023/02/26 03:44:45 Pushing image: a9df04dede0641e0b00838f7861296d3.azurecr.io/azureml/azureml_eb4ae1f22a6b9a15bc42fb135660daf8:1, attempt 1\nThe push refers to repository [a9df04dede0641e0b00838f7861296d3.azurecr.io/azureml/azureml_eb4ae1f22a6b9a15bc42fb135660daf8]\n7033a1e7359e: Preparing\n1e2c3dbdc18e: Preparing\nfcd6374f6989: Preparing\n5f08cde7c4cc: Preparing\na09f28e0cd2d: Preparing\nae5283a2ba7a: Preparing\n4aa28cf1cbe1: Preparing\nc7cf944803c8: Preparing\nf1cd43382cdd: Preparing\n7b7ed5d1379b: Preparing\n2bcdf82aed44: Preparing\nb21e039321ee: Preparing\n445a2d2462f0: Preparing\n6e539e6b11c3: Preparing\nb67f8b8feccd: Preparing\n7e60813e02c4: Preparing\n0d66ccba1288: Preparing\n20b46ade1e43: Preparing\n21d33b1352c9: Preparing\naf7ed92504ae: Preparing\nae5283a2ba7a: Waiting\n4aa28cf1cbe1: Waiting\nc7cf944803c8: Waiting\nf1cd43382cdd: Waiting\n7b7ed5d1379b: Waiting\n2bcdf82aed44: Waiting\nb21e039321ee: Waiting\n445a2d2462f0: Waiting\n6e539e6b11c3: Waiting\nb67f8b8feccd: Waiting\n7e60813e02c4: Waiting\n0d66ccba1288: Waiting\n20b46ade1e43: Waiting\n21d33b1352c9: Waiting\naf7ed92504ae: Waiting\na09f28e0cd2d: Pushed\n1e2c3dbdc18e: Pushed\n7033a1e7359e: Pushed\n5f08cde7c4cc: Pushed\nfcd6374f6989: Pushed\n4aa28cf1cbe1: Pushed\nc7cf944803c8: Pushed\nf1cd43382cdd: Pushed\n7b7ed5d1379b: Pushed\n2bcdf82aed44: Pushed\nb21e039321ee: Pushed\n7e60813e02c4: Pushed\n445a2d2462f0: Pushed\n6e539e6b11c3: Pushed\n0d66ccba1288: Pushed\n20b46ade1e43: Pushed\naf7ed92504ae: Pushed\nb67f8b8feccd: Pushed\n21d33b1352c9: Pushed\nae5283a2ba7a: Pushed\n1: digest: sha256:71062ac61f5fb50476095b9941efe987d8c228b28e6ef64869ab56e68fd3f6dc size: 4514\n2023/02/26 03:46:40 Successfully pushed image: a9df04dede0641e0b00838f7861296d3.azurecr.io/azureml/azureml_eb4ae1f22a6b9a15bc42fb135660daf8:1\n2023/02/26 03:46:40 Executing step ID: acb_step_2. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n2023/02/26 03:46:40 Pushing image: a9df04dede0641e0b00838f7861296d3.azurecr.io/azureml/azureml_eb4ae1f22a6b9a15bc42fb135660daf8:latest, attempt 1\nThe push refers to repository [a9df04dede0641e0b00838f7861296d3.azurecr.io/azureml/azureml_eb4ae1f22a6b9a15bc42fb135660daf8]\n7033a1e7359e: Preparing\n1e2c3dbdc18e: Preparing\nfcd6374f6989: Preparing\n5f08cde7c4cc: Preparing\na09f28e0cd2d: Preparing\nae5283a2ba7a: Preparing\n4aa28cf1cbe1: Preparing\nc7cf944803c8: Preparing\nf1cd43382cdd: Preparing\n7b7ed5d1379b: Preparing\n2bcdf82aed44: Preparing\nb21e039321ee: Preparing\n445a2d2462f0: Preparing\n6e539e6b11c3: Preparing\nb67f8b8feccd: Preparing\n7e60813e02c4: Preparing\n0d66ccba1288: Preparing\n20b46ade1e43: Preparing\n21d33b1352c9: Preparing\naf7ed92504ae: Preparing\n445a2d2462f0: Waiting\n6e539e6b11c3: Waiting\nae5283a2ba7a: Waiting\nb67f8b8feccd: Waiting\n4aa28cf1cbe1: Waiting\n7e60813e02c4: Waiting\nc7cf944803c8: Waiting\n0d66ccba1288: Waiting\n20b46ade1e43: Waiting\nf1cd43382cdd: Waiting\n21d33b1352c9: Waiting\naf7ed92504ae: Waiting\n7b7ed5d1379b: Waiting\nb21e039321ee: Waiting\n2bcdf82aed44: Waiting\n5f08cde7c4cc: Layer already exists\nfcd6374f6989: Layer already exists\n1e2c3dbdc18e: Layer already exists\n7033a1e7359e: Layer already exists\na09f28e0cd2d: Layer already exists\nae5283a2ba7a: Layer already exists\n7b7ed5d1379b: Layer already exists\n4aa28cf1cbe1: Layer already exists\nf1cd43382cdd: Layer already exists\nc7cf944803c8: Layer already exists\n2bcdf82aed44: Layer already exists\n6e539e6b11c3: Layer already exists\n445a2d2462f0: Layer already exists\nb21e039321ee: Layer already exists\n0d66ccba1288: Layer already exists\n20b46ade1e43: Layer already exists\n7e60813e02c4: Layer already exists\naf7ed92504ae: Layer already exists\n21d33b1352c9: Layer already exists\nb67f8b8feccd: Layer already exists\nlatest: digest: sha256:71062ac61f5fb50476095b9941efe987d8c228b28e6ef64869ab56e68fd3f6dc size: 4514\n2023/02/26 03:46:44 Successfully pushed image: a9df04dede0641e0b00838f7861296d3.azurecr.io/azureml/azureml_eb4ae1f22a6b9a15bc42fb135660daf8:latest\n2023/02/26 03:46:44 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 158.818280)\n2023/02/26 03:46:44 Populating digests for step ID: acb_step_0...\n2023/02/26 03:46:46 Successfully populated digests for step ID: acb_step_0\n2023/02/26 03:46:46 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 114.927803)\n2023/02/26 03:46:46 Step ID: acb_step_2 marked as successful (elapsed time in seconds: 4.120632)\n2023/02/26 03:46:46 The following dependencies were found:\n2023/02/26 03:46:46 \n- image:\n    registry: a9df04dede0641e0b00838f7861296d3.azurecr.io\n    repository: azureml/azureml_eb4ae1f22a6b9a15bc42fb135660daf8\n    tag: latest\n    digest: sha256:71062ac61f5fb50476095b9941efe987d8c228b28e6ef64869ab56e68fd3f6dc\n  runtime-dependency:\n    registry: mcr.microsoft.com\n    repository: azureml/openmpi4.1.0-ubuntu20.04\n    tag: 20221101.v1\n    digest: sha256:4505a963b2d34a42b5eaef48b8142ca98123d05d3a95eee3fe57551570a70e3b\n  git: {}\n- image:\n    registry: a9df04dede0641e0b00838f7861296d3.azurecr.io\n    repository: azureml/azureml_eb4ae1f22a6b9a15bc42fb135660daf8\n    tag: \"1\"\n    digest: sha256:71062ac61f5fb50476095b9941efe987d8c228b28e6ef64869ab56e68fd3f6dc\n  runtime-dependency:\n    registry: mcr.microsoft.com\n    repository: azureml/openmpi4.1.0-ubuntu20.04\n    tag: 20221101.v1\n    digest: sha256:4505a963b2d34a42b5eaef48b8142ca98123d05d3a95eee3fe57551570a70e3b\n  git: {}\n\n\nRun ID: ch1 was successful after 4m43s\n\nStepRun(Prepare Data) Execution Summary\n========================================\nStepRun( Prepare Data ) Status: Finished\n{'runId': '28412720-e492-40ef-b6ab-757ce5323bcf', 'target': 'sweetdreams', 'status': 'Completed', 'startTimeUtc': '2023-02-26T03:55:58.283069Z', 'endTimeUtc': '2023-02-26T03:59:27.437994Z', 'services': {}, 'properties': {'ContentSnapshotId': 'efa588c2-f3fa-4434-8833-4c840944821a', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': 'be8645cd-8cfd-4d67-b3a9-62678beab6d5', 'azureml.moduleName': 'Prepare Data', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '932d89eb', 'azureml.pipelinerunid': '46519ae6-2df9-4478-89bf-c01cda5c2aff', 'azureml.pipeline': '46519ae6-2df9-4478-89bf-c01cda5c2aff', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlctrain', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '783b508b-95f4-4f74-900f-7fa9508774fd'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'raw_data', 'mechanism': 'Direct'}}], 'outputDatasets': [{'identifier': {'savedId': 'be79e22c-9925-4e53-be9b-91e1bc725f32'}, 'outputType': 'RunOutput', 'outputDetails': {'outputName': 'prepped_data'}, 'dataset': {\n  \"source\": [\n    \"('workspaceblobstore', 'dataset/28412720-e492-40ef-b6ab-757ce5323bcf/prepped_data/')\"\n  ],\n  \"definition\": [\n    \"GetDatastoreFiles\"\n  ],\n  \"registration\": {\n    \"id\": \"be79e22c-9925-4e53-be9b-91e1bc725f32\",\n    \"name\": null,\n    \"version\": null,\n    \"workspace\": \"Workspace.create(name='testerinois', subscription_id='71fa0172-ce90-403c-94a9-14ce1e88f56a', resource_group='rg_eastus_44930_1_1677382226452')\"\n  }\n}}], 'runDefinition': {'script': 'prep_titanic.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--input-data', 'DatasetConsumptionConfig:raw_data', '--prepped-data', 'DatasetOutputConfig:prepped_data'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'sweetdreams', 'dataReferences': {}, 'data': {'raw_data': {'dataLocation': {'dataset': {'id': '783b508b-95f4-4f74-900f-7fa9508774fd', 'name': None, 'version': '1'}, 'dataPath': None, 'uri': None, 'type': None}, 'mechanism': 'Direct', 'environmentVariableName': 'raw_data', 'pathOnCompute': None, 'overwrite': False, 'options': None}}, 'outputData': {'prepped_data': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'workspaceblobstore', 'relativePath': None}, 'uri': None, 'type': None}, 'mechanism': 'Mount', 'additionalOptions': {'pathOnCompute': None, 'registrationOptions': {'name': None, 'description': None, 'tags': None, 'properties': {'azureml.pipelineRunId': '46519ae6-2df9-4478-89bf-c01cda5c2aff', 'azureml.pipelineRun.moduleNodeId': '932d89eb', 'azureml.pipelineRun.outputPortName': 'prepped_data'}, 'datasetRegistrationOptions': {'additionalTransformation': None}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}, 'environmentVariableName': None}}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'experiment_env', 'version': '1', 'assetId': 'azureml://locations/eastus2/workspaces/a9df04de-de06-41e0-b008-38f7861296d3/environments/experiment_env/versions/1', 'autoRebuild': True, 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'name': 'experiment_env', 'dependencies': ['python=3.6.2', 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip', {'pip': ['azureml-defaults', 'pyarrow']}]}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221101.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://testerinois6943754373.blob.core.windows.net/azureml/ExperimentRun/dcid.28412720-e492-40ef-b6ab-757ce5323bcf/azureml-logs/20_image_build_log.txt?sv=2019-07-07&sr=b&sig=%2Bil1wxBz1aevTmL9jgm9%2BBuyErLb3sPU0D%2B967yoBag%3D&skoid=4b71d3f9-8a02-4b54-99c7-b88484da6ba1&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-26T03%3A31%3A45Z&ske=2023-02-27T11%3A41%3A45Z&sks=b&skv=2019-07-07&st=2023-02-26T03%3A47%3A34Z&se=2023-02-26T11%3A57%3A34Z&sp=r', 'logs/azureml/dataprep/0/backgroundProcess.log': 'https://testerinois6943754373.blob.core.windows.net/azureml/ExperimentRun/dcid.28412720-e492-40ef-b6ab-757ce5323bcf/logs/azureml/dataprep/0/backgroundProcess.log?sv=2019-07-07&sr=b&sig=pCfPeexKV3Nd75WELufJbj2ryqvenTIlHOgg%2Ft%2FYP%2Bc%3D&skoid=4b71d3f9-8a02-4b54-99c7-b88484da6ba1&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-26T03%3A31%3A45Z&ske=2023-02-27T11%3A41%3A45Z&sks=b&skv=2019-07-07&st=2023-02-26T03%3A49%3A21Z&se=2023-02-26T11%3A59%3A21Z&sp=r', 'logs/azureml/dataprep/0/backgroundProcess_Telemetry.log': 'https://testerinois6943754373.blob.core.windows.net/azureml/ExperimentRun/dcid.28412720-e492-40ef-b6ab-757ce5323bcf/logs/azureml/dataprep/0/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=6YTuf6sk7nFBopJ90psMFlH0YZTKmFLUE4WNJVEkMEM%3D&skoid=4b71d3f9-8a02-4b54-99c7-b88484da6ba1&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-26T03%3A31%3A45Z&ske=2023-02-27T11%3A41%3A45Z&sks=b&skv=2019-07-07&st=2023-02-26T03%3A49%3A21Z&se=2023-02-26T11%3A59%3A21Z&sp=r', 'logs/azureml/dataprep/0/rslex.log.2023-02-26-03': 'https://testerinois6943754373.blob.core.windows.net/azureml/ExperimentRun/dcid.28412720-e492-40ef-b6ab-757ce5323bcf/logs/azureml/dataprep/0/rslex.log.2023-02-26-03?sv=2019-07-07&sr=b&sig=8qYRkYU5J8pwCp28O9UNstxGU%2FskVqXHmmDLHfWkM7I%3D&skoid=4b71d3f9-8a02-4b54-99c7-b88484da6ba1&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-26T03%3A31%3A45Z&ske=2023-02-27T11%3A41%3A45Z&sks=b&skv=2019-07-07&st=2023-02-26T03%3A49%3A21Z&se=2023-02-26T11%3A59%3A21Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://testerinois6943754373.blob.core.windows.net/azureml/ExperimentRun/dcid.28412720-e492-40ef-b6ab-757ce5323bcf/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=xv7kRtRRJM56%2BwK8lyw%2BZetLhLuFm%2FYMzfeelVw%2F2GQ%3D&skoid=4b71d3f9-8a02-4b54-99c7-b88484da6ba1&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-26T03%3A31%3A45Z&ske=2023-02-27T11%3A41%3A45Z&sks=b&skv=2019-07-07&st=2023-02-26T03%3A49%3A21Z&se=2023-02-26T11%3A59%3A21Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://testerinois6943754373.blob.core.windows.net/azureml/ExperimentRun/dcid.28412720-e492-40ef-b6ab-757ce5323bcf/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=t9tks1Tmu8jqaFbox6D69gld8p5IAQ6mpd2vVm23NDA%3D&skoid=4b71d3f9-8a02-4b54-99c7-b88484da6ba1&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-26T03%3A31%3A45Z&ske=2023-02-27T11%3A41%3A45Z&sks=b&skv=2019-07-07&st=2023-02-26T03%3A49%3A21Z&se=2023-02-26T11%3A59%3A21Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://testerinois6943754373.blob.core.windows.net/azureml/ExperimentRun/dcid.28412720-e492-40ef-b6ab-757ce5323bcf/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=J3oPLTV5TzYRv7p6NSDWGz47xiOwhY84jiuD2ZavyBw%3D&skoid=4b71d3f9-8a02-4b54-99c7-b88484da6ba1&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-26T03%3A31%3A45Z&ske=2023-02-27T11%3A41%3A45Z&sks=b&skv=2019-07-07&st=2023-02-26T03%3A49%3A21Z&se=2023-02-26T11%3A59%3A21Z&sp=r', 'user_logs/std_log.txt': 'https://testerinois6943754373.blob.core.windows.net/azureml/ExperimentRun/dcid.28412720-e492-40ef-b6ab-757ce5323bcf/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=3j%2B%2B08PogJM9KsxCtKUWOiPF14OVuDCqLwr3YU9MlYg%3D&skoid=4b71d3f9-8a02-4b54-99c7-b88484da6ba1&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-26T03%3A31%3A45Z&ske=2023-02-27T11%3A41%3A45Z&sks=b&skv=2019-07-07&st=2023-02-26T03%3A49%3A29Z&se=2023-02-26T11%3A59%3A29Z&sp=r', 'system_logs/cs_capability/cs-capability.log': 'https://testerinois6943754373.blob.core.windows.net/azureml/ExperimentRun/dcid.28412720-e492-40ef-b6ab-757ce5323bcf/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=Wc58fVgWvLBM0dR%2BaeoytAjtTZkRhXxQBkqENacm%2FYw%3D&skoid=4b71d3f9-8a02-4b54-99c7-b88484da6ba1&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-26T03%3A31%3A45Z&ske=2023-02-27T11%3A41%3A45Z&sks=b&skv=2019-07-07&st=2023-02-26T03%3A49%3A29Z&se=2023-02-26T11%3A59%3A29Z&sp=r', 'system_logs/data_capability/data-capability.log': 'https://testerinois6943754373.blob.core.windows.net/azureml/ExperimentRun/dcid.28412720-e492-40ef-b6ab-757ce5323bcf/system_logs/data_capability/data-capability.log?sv=2019-07-07&sr=b&sig=uxs2w%2BLX67ZwDFfRMrUYzmkEemZfChI2%2BAF6waCd2rg%3D&skoid=4b71d3f9-8a02-4b54-99c7-b88484da6ba1&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-26T03%3A31%3A45Z&ske=2023-02-27T11%3A41%3A45Z&sks=b&skv=2019-07-07&st=2023-02-26T03%3A49%3A29Z&se=2023-02-26T11%3A59%3A29Z&sp=r', 'system_logs/data_capability/rslex.log.2023-02-26-03': 'https://testerinois6943754373.blob.core.windows.net/azureml/ExperimentRun/dcid.28412720-e492-40ef-b6ab-757ce5323bcf/system_logs/data_capability/rslex.log.2023-02-26-03?sv=2019-07-07&sr=b&sig=8wxO3gbuhSypW85WGshxjl6pAh8y68yKQMPi2R0a12M%3D&skoid=4b71d3f9-8a02-4b54-99c7-b88484da6ba1&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-26T03%3A31%3A45Z&ske=2023-02-27T11%3A41%3A45Z&sks=b&skv=2019-07-07&st=2023-02-26T03%3A49%3A29Z&se=2023-02-26T11%3A59%3A29Z&sp=r', 'system_logs/hosttools_capability/hosttools-capability.log': 'https://testerinois6943754373.blob.core.windows.net/azureml/ExperimentRun/dcid.28412720-e492-40ef-b6ab-757ce5323bcf/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=vhG7G1QOmEzyo5%2By4PBq5J4HVwtPSn4TNmPDvnacKiY%3D&skoid=4b71d3f9-8a02-4b54-99c7-b88484da6ba1&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-26T03%3A31%3A45Z&ske=2023-02-27T11%3A41%3A45Z&sks=b&skv=2019-07-07&st=2023-02-26T03%3A49%3A29Z&se=2023-02-26T11%3A59%3A29Z&sp=r', 'system_logs/lifecycler/execution-wrapper.log': 'https://testerinois6943754373.blob.core.windows.net/azureml/ExperimentRun/dcid.28412720-e492-40ef-b6ab-757ce5323bcf/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=A4hZ99yJl4GJOyuax4nNjEKux9HP2pYCWrrAWrVDxlQ%3D&skoid=4b71d3f9-8a02-4b54-99c7-b88484da6ba1&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-26T03%3A31%3A45Z&ske=2023-02-27T11%3A41%3A45Z&sks=b&skv=2019-07-07&st=2023-02-26T03%3A49%3A29Z&se=2023-02-26T11%3A59%3A29Z&sp=r', 'system_logs/lifecycler/lifecycler.log': 'https://testerinois6943754373.blob.core.windows.net/azureml/ExperimentRun/dcid.28412720-e492-40ef-b6ab-757ce5323bcf/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=wdPbwHd7Q8jyiI52ixfgfB%2F6%2BeydoUn43nNmawxM2Gw%3D&skoid=4b71d3f9-8a02-4b54-99c7-b88484da6ba1&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-26T03%3A31%3A45Z&ske=2023-02-27T11%3A41%3A45Z&sks=b&skv=2019-07-07&st=2023-02-26T03%3A49%3A29Z&se=2023-02-26T11%3A59%3A29Z&sp=r', 'system_logs/metrics_capability/metrics-capability.log': 'https://testerinois6943754373.blob.core.windows.net/azureml/ExperimentRun/dcid.28412720-e492-40ef-b6ab-757ce5323bcf/system_logs/metrics_capability/metrics-capability.log?sv=2019-07-07&sr=b&sig=1p%2BNtfYRicy0yAH5VjnRQwUuqihPpHRa8ul6%2Bhb8Io8%3D&skoid=4b71d3f9-8a02-4b54-99c7-b88484da6ba1&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-26T03%3A31%3A45Z&ske=2023-02-27T11%3A41%3A45Z&sks=b&skv=2019-07-07&st=2023-02-26T03%3A49%3A29Z&se=2023-02-26T11%3A59%3A29Z&sp=r', 'system_logs/snapshot_capability/snapshot-capability.log': 'https://testerinois6943754373.blob.core.windows.net/azureml/ExperimentRun/dcid.28412720-e492-40ef-b6ab-757ce5323bcf/system_logs/snapshot_capability/snapshot-capability.log?sv=2019-07-07&sr=b&sig=2VKQfwMCuhv2ASi1TJYRywKuRuBocUpx63gj9kJfleg%3D&skoid=4b71d3f9-8a02-4b54-99c7-b88484da6ba1&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-26T03%3A31%3A45Z&ske=2023-02-27T11%3A41%3A45Z&sks=b&skv=2019-07-07&st=2023-02-26T03%3A49%3A29Z&se=2023-02-26T11%3A59%3A29Z&sp=r'}, 'submittedBy': 'labuser_44930_70189456'}\n\n\n\n\nStepRunId: 0d8f69ed-8051-43ee-b62f-d0e96c7b3d44\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/0d8f69ed-8051-43ee-b62f-d0e96c7b3d44?wsid=/subscriptions/71fa0172-ce90-403c-94a9-14ce1e88f56a/resourcegroups/rg_eastus_44930_1_1677382226452/workspaces/testerinois&tid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3\nStepRun( Train and Register Model ) Status: NotStarted\nStepRun( Train and Register Model ) Status: Running\n\nStepRun(Train and Register Model) Execution Summary\n====================================================\nStepRun( Train and Register Model ) Status: Finished\n{'runId': '0d8f69ed-8051-43ee-b62f-d0e96c7b3d44', 'target': 'sweetdreams', 'status': 'Completed', 'startTimeUtc': '2023-02-26T03:59:38.913273Z', 'endTimeUtc': '2023-02-26T04:00:01.05428Z', 'services': {}, 'properties': {'ContentSnapshotId': 'efa588c2-f3fa-4434-8833-4c840944821a', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '3e919d11-a94f-4d12-b081-634b28aac829', 'azureml.moduleName': 'Train and Register Model', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '419c466c', 'azureml.pipelinerunid': '46519ae6-2df9-4478-89bf-c01cda5c2aff', 'azureml.pipeline': '46519ae6-2df9-4478-89bf-c01cda5c2aff', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlctrain', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': 'be79e22c-9925-4e53-be9b-91e1bc725f32'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'input_c35d7190', 'mechanism': 'Mount'}}], 'outputDatasets': [], 'runDefinition': {'script': 'train_titanic.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--training-data', 'DatasetConsumptionConfig:input_c35d7190'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'sweetdreams', 'dataReferences': {}, 'data': {'input_c35d7190': {'dataLocation': {'dataset': {'id': 'be79e22c-9925-4e53-be9b-91e1bc725f32', 'name': None, 'version': None}, 'dataPath': None, 'uri': None, 'type': None}, 'mechanism': 'Mount', 'environmentVariableName': 'input_c35d7190', 'pathOnCompute': None, 'overwrite': False, 'options': None}}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'experiment_env', 'version': '1', 'assetId': 'azureml://locations/eastus2/workspaces/a9df04de-de06-41e0-b008-38f7861296d3/environments/experiment_env/versions/1', 'autoRebuild': True, 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'name': 'experiment_env', 'dependencies': ['python=3.6.2', 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip', {'pip': ['azureml-defaults', 'pyarrow']}]}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221101.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'logs/azureml/executionlogs.txt': 'https://testerinois6943754373.blob.core.windows.net/azureml/ExperimentRun/dcid.0d8f69ed-8051-43ee-b62f-d0e96c7b3d44/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=Q9u7h8B0ct4osAb%2FXvgTBME1aH%2BZaPMJvKsdkbD9sTk%3D&skoid=4b71d3f9-8a02-4b54-99c7-b88484da6ba1&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-26T03%3A31%3A45Z&ske=2023-02-27T11%3A41%3A45Z&sks=b&skv=2019-07-07&st=2023-02-26T03%3A49%3A36Z&se=2023-02-26T11%3A59%3A36Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://testerinois6943754373.blob.core.windows.net/azureml/ExperimentRun/dcid.0d8f69ed-8051-43ee-b62f-d0e96c7b3d44/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=KeEfiEZ1BExZtcKiYBjfrIUVD1oKrPAMuK9a%2Fpy76GM%3D&skoid=4b71d3f9-8a02-4b54-99c7-b88484da6ba1&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-26T03%3A31%3A45Z&ske=2023-02-27T11%3A41%3A45Z&sks=b&skv=2019-07-07&st=2023-02-26T03%3A49%3A36Z&se=2023-02-26T11%3A59%3A36Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://testerinois6943754373.blob.core.windows.net/azureml/ExperimentRun/dcid.0d8f69ed-8051-43ee-b62f-d0e96c7b3d44/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=2kMbT2mDir3eLfS%2BxlKYfSJo0uCL9xDYifQWh5FC8uc%3D&skoid=4b71d3f9-8a02-4b54-99c7-b88484da6ba1&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-26T03%3A31%3A45Z&ske=2023-02-27T11%3A41%3A45Z&sks=b&skv=2019-07-07&st=2023-02-26T03%3A49%3A36Z&se=2023-02-26T11%3A59%3A36Z&sp=r', 'user_logs/std_log.txt': 'https://testerinois6943754373.blob.core.windows.net/azureml/ExperimentRun/dcid.0d8f69ed-8051-43ee-b62f-d0e96c7b3d44/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=KLz%2BKLGVNeEVN%2FYPG%2BPRDWLxhGuKBJl%2BsFdf%2BTgVGrg%3D&skoid=4b71d3f9-8a02-4b54-99c7-b88484da6ba1&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-26T03%3A31%3A45Z&ske=2023-02-27T11%3A41%3A45Z&sks=b&skv=2019-07-07&st=2023-02-26T03%3A50%3A02Z&se=2023-02-26T12%3A00%3A02Z&sp=r', 'system_logs/cs_capability/cs-capability.log': 'https://testerinois6943754373.blob.core.windows.net/azureml/ExperimentRun/dcid.0d8f69ed-8051-43ee-b62f-d0e96c7b3d44/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=vNQp1XAengcoXR690y3bBp9P9fC2EbmQARLcJuj5gTE%3D&skoid=4b71d3f9-8a02-4b54-99c7-b88484da6ba1&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-26T03%3A31%3A45Z&ske=2023-02-27T11%3A41%3A45Z&sks=b&skv=2019-07-07&st=2023-02-26T03%3A50%3A03Z&se=2023-02-26T12%3A00%3A03Z&sp=r', 'system_logs/data_capability/data-capability.log': 'https://testerinois6943754373.blob.core.windows.net/azureml/ExperimentRun/dcid.0d8f69ed-8051-43ee-b62f-d0e96c7b3d44/system_logs/data_capability/data-capability.log?sv=2019-07-07&sr=b&sig=ZlRVvOkI2lkuVHUBnaUKygMCkSyEJcd3Lv0cNae0Hm0%3D&skoid=4b71d3f9-8a02-4b54-99c7-b88484da6ba1&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-26T03%3A31%3A45Z&ske=2023-02-27T11%3A41%3A45Z&sks=b&skv=2019-07-07&st=2023-02-26T03%3A50%3A03Z&se=2023-02-26T12%3A00%3A03Z&sp=r', 'system_logs/data_capability/rslex.log.2023-02-26-03': 'https://testerinois6943754373.blob.core.windows.net/azureml/ExperimentRun/dcid.0d8f69ed-8051-43ee-b62f-d0e96c7b3d44/system_logs/data_capability/rslex.log.2023-02-26-03?sv=2019-07-07&sr=b&sig=8NPDz1XkZ21cHd%2BmaNs8DKn%2FTEP4Th%2FdULlRllkmEuw%3D&skoid=4b71d3f9-8a02-4b54-99c7-b88484da6ba1&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-26T03%3A31%3A45Z&ske=2023-02-27T11%3A41%3A45Z&sks=b&skv=2019-07-07&st=2023-02-26T03%3A50%3A03Z&se=2023-02-26T12%3A00%3A03Z&sp=r', 'system_logs/hosttools_capability/hosttools-capability.log': 'https://testerinois6943754373.blob.core.windows.net/azureml/ExperimentRun/dcid.0d8f69ed-8051-43ee-b62f-d0e96c7b3d44/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=Yg4FCIUceeAM4BAf%2FRIX4qgf%2BRWMcU7EPojAx3qKnZw%3D&skoid=4b71d3f9-8a02-4b54-99c7-b88484da6ba1&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-26T03%3A31%3A45Z&ske=2023-02-27T11%3A41%3A45Z&sks=b&skv=2019-07-07&st=2023-02-26T03%3A50%3A03Z&se=2023-02-26T12%3A00%3A03Z&sp=r', 'system_logs/lifecycler/execution-wrapper.log': 'https://testerinois6943754373.blob.core.windows.net/azureml/ExperimentRun/dcid.0d8f69ed-8051-43ee-b62f-d0e96c7b3d44/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=Ufhd9mK%2FD0%2BxdIwcjU6kg34jRbtm7uYFtnMfrG4EZ50%3D&skoid=4b71d3f9-8a02-4b54-99c7-b88484da6ba1&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-26T03%3A31%3A45Z&ske=2023-02-27T11%3A41%3A45Z&sks=b&skv=2019-07-07&st=2023-02-26T03%3A50%3A03Z&se=2023-02-26T12%3A00%3A03Z&sp=r', 'system_logs/lifecycler/lifecycler.log': 'https://testerinois6943754373.blob.core.windows.net/azureml/ExperimentRun/dcid.0d8f69ed-8051-43ee-b62f-d0e96c7b3d44/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=Z7RMiAR8HPWDD0ZP%2F3dTn82hniEs8ZHXDLpyGPCSMyQ%3D&skoid=4b71d3f9-8a02-4b54-99c7-b88484da6ba1&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-26T03%3A31%3A45Z&ske=2023-02-27T11%3A41%3A45Z&sks=b&skv=2019-07-07&st=2023-02-26T03%3A50%3A03Z&se=2023-02-26T12%3A00%3A03Z&sp=r', 'system_logs/metrics_capability/metrics-capability.log': 'https://testerinois6943754373.blob.core.windows.net/azureml/ExperimentRun/dcid.0d8f69ed-8051-43ee-b62f-d0e96c7b3d44/system_logs/metrics_capability/metrics-capability.log?sv=2019-07-07&sr=b&sig=krC32QGHawHKrINs1t2jhsFeAh8RlVDxzY02nS%2FHFF0%3D&skoid=4b71d3f9-8a02-4b54-99c7-b88484da6ba1&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-26T03%3A31%3A45Z&ske=2023-02-27T11%3A41%3A45Z&sks=b&skv=2019-07-07&st=2023-02-26T03%3A50%3A03Z&se=2023-02-26T12%3A00%3A03Z&sp=r', 'system_logs/snapshot_capability/snapshot-capability.log': 'https://testerinois6943754373.blob.core.windows.net/azureml/ExperimentRun/dcid.0d8f69ed-8051-43ee-b62f-d0e96c7b3d44/system_logs/snapshot_capability/snapshot-capability.log?sv=2019-07-07&sr=b&sig=YE8y88WAM4UHck4PGSeEKDb%2FNfGpZfQNp2AUGpB1B2s%3D&skoid=4b71d3f9-8a02-4b54-99c7-b88484da6ba1&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-26T03%3A31%3A45Z&ske=2023-02-27T11%3A41%3A45Z&sks=b&skv=2019-07-07&st=2023-02-26T03%3A50%3A03Z&se=2023-02-26T12%3A00%3A03Z&sp=r'}, 'submittedBy': 'labuser_44930_70189456'}\n\n\n\nPipelineRun Execution Summary\n==============================\nPipelineRun Status: Finished\n{'runId': '46519ae6-2df9-4478-89bf-c01cda5c2aff', 'status': 'Completed', 'startTimeUtc': '2023-02-26T03:41:44.908179Z', 'endTimeUtc': '2023-02-26T04:00:02.124482Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}', 'azureml.continue_on_step_failure': 'False', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.pipelineComponent': 'pipelinerun', 'azureml.pipelines.stages': '{\"Initialization\":null,\"Execution\":{\"StartTime\":\"2023-02-26T03:41:45.2309061+00:00\",\"EndTime\":\"2023-02-26T04:00:02.0594978+00:00\",\"Status\":\"Finished\"}}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://testerinois6943754373.blob.core.windows.net/azureml/ExperimentRun/dcid.46519ae6-2df9-4478-89bf-c01cda5c2aff/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=ZQhL3MfD4NT5UX5o5UEyhaQdrVvC2ZbjHk3WnJf21Ts%3D&skoid=4b71d3f9-8a02-4b54-99c7-b88484da6ba1&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-26T03%3A31%3A45Z&ske=2023-02-27T11%3A41%3A45Z&sks=b&skv=2019-07-07&st=2023-02-26T03%3A48%3A14Z&se=2023-02-26T11%3A58%3A14Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://testerinois6943754373.blob.core.windows.net/azureml/ExperimentRun/dcid.46519ae6-2df9-4478-89bf-c01cda5c2aff/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=kDs2vseqgf2%2FDPniH3Kv6pcB3cH32SA9j9%2FAOI1F5lA%3D&skoid=4b71d3f9-8a02-4b54-99c7-b88484da6ba1&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-26T03%3A31%3A45Z&ske=2023-02-27T11%3A41%3A45Z&sks=b&skv=2019-07-07&st=2023-02-26T03%3A48%3A14Z&se=2023-02-26T11%3A58%3A14Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://testerinois6943754373.blob.core.windows.net/azureml/ExperimentRun/dcid.46519ae6-2df9-4478-89bf-c01cda5c2aff/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=AJBtY7TP%2BFZ5AmZsQ2t6XKGKt4%2FmnTATSveDPyk%2F830%3D&skoid=4b71d3f9-8a02-4b54-99c7-b88484da6ba1&sktid=82676786-5bc7-43c6-b8f8-b3ee02b0b5f3&skt=2023-02-26T03%3A31%3A45Z&ske=2023-02-27T11%3A41%3A45Z&sks=b&skv=2019-07-07&st=2023-02-26T03%3A48%3A14Z&se=2023-02-26T11%3A58%3A14Z&sp=r'}, 'submittedBy': 'labuser_44930_70189456'}\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "'Finished'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677384004858
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for run in pipeline_run.get_children():\r\n",
        "    print(run.name, ':')\r\n",
        "    metrics = run.get_metrics()\r\n",
        "    for metric_name in metrics:\r\n",
        "        print('\\t',metric_name, \":\", metrics[metric_name])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Train and Register Model :\n\t Accuracy : 0.7837837837837838\n\t AUC : 0.8788819875776397\n\t ROC : aml://artifactId/ExperimentRun/dcid.0d8f69ed-8051-43ee-b62f-d0e96c7b3d44/ROC_1677383987.png\nPrepare Data :\n\t raw_rows : 891\n\t processed_rows : 183\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677384006122
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "\r\n",
        "# Create a folder for the deployment files\r\n",
        "deployment_folder = './titanic_service'\r\n",
        "os.makedirs(deployment_folder, exist_ok=True)\r\n",
        "print(deployment_folder, 'folder created.')\r\n",
        "\r\n",
        "# Set path for scoring script\r\n",
        "script_file = 'score_titanic.py'\r\n",
        "script_path = os.path.join(deployment_folder,script_file)\r\n",
        "     "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "./titanic_service folder created.\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677384006533
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $script_path\r\n",
        "import json\r\n",
        "import joblib\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "\r\n",
        "# Called when the service is loaded\r\n",
        "def init():\r\n",
        "    global model\r\n",
        "    # Get the path to the deployed model file and load it\r\n",
        "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'titanic_model.pkl')\r\n",
        "    model = joblib.load(model_path)\r\n",
        "\r\n",
        "\r\n",
        "# Called when a request is received\r\n",
        "def run(raw_data):\r\n",
        "    # Get the input data as a numpy array\r\n",
        "    data = np.array(json.loads(raw_data)['data'])\r\n",
        "\r\n",
        "    # Get a prediction from the model\r\n",
        "    predictions = model.predict(data)\r\n",
        "    # Get the corresponding classname for each prediction (0 or 1)\r\n",
        "    classnames = ['Non-Survived', 'Survived']\r\n",
        "    predicted_classes = []\r\n",
        "    for prediction in predictions:\r\n",
        "        predicted_classes.append(classnames[prediction])\r\n",
        "    # Return the predictions as JSON\r\n",
        "    return json.dumps(predicted_classes)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./titanic_service/score_titanic.py\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ws.models['titanic_model']\r\n",
        "print(model.name, 'version', model.version)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "titanic_model version 1\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677384007277
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\r\n",
        "from azureml.core.model import InferenceConfig\r\n",
        "from azureml.core.webservice import AciWebservice\r\n",
        "from azureml.core import Model\r\n",
        "\r\n",
        "# Configure the scoring environment\r\n",
        "service_env = Environment.get(workspace=ws, name=\"AzureML-sklearn-0.24.1-ubuntu18.04-py37-cpu-inference\")\r\n",
        "service_env.inferencing_stack_version=\"latest\"\r\n",
        "\r\n",
        "inference_config = InferenceConfig(source_directory=deployment_folder,\r\n",
        "                                   entry_script=script_file,\r\n",
        "                                   environment=service_env)\r\n",
        "\r\n",
        "# Configure the web service container\r\n",
        "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\r\n",
        "\r\n",
        "# Deploy the model as a service\r\n",
        "print('Deploying model...')\r\n",
        "service_name = \"titanic-service\"\r\n",
        "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, overwrite=True)\r\n",
        "service.wait_for_deployment(True)\r\n",
        "print(service.state)\r\n",
        "     "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Deploying model...\nTips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\nRunning\n2023-02-26 04:00:08+00:00 Creating Container Registry if not exists.\n2023-02-26 04:00:08+00:00 Registering the environment.\n2023-02-26 04:00:09+00:00 Use the existing image.\n2023-02-26 04:00:09+00:00 Submitting deployment to compute.\n2023-02-26 04:00:15+00:00 Checking the status of deployment titanic-service..\n2023-02-26 04:01:29+00:00 Checking the status of inference endpoint titanic-service.\nSucceeded\nACI service creation operation finished, operation \"Succeeded\"\nHealthy\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677384108827
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for webservice_name in ws.webservices:\r\n",
        "    print(webservice_name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "titanic-service\n"
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677384109231
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'titanic-data/titanic_scaler.pkl'\r\n",
        "datastore = Datastore.get(ws, \"workspaceblobstore\")\r\n",
        "scalar_file = Dataset.File.from_files(path=(datastore, path))\r\n",
        "#mounted_path = scalar_file.mount()\r\n",
        "\r\n",
        "scalar_file.download(target_path='./titanic_service')"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": "['/mnt/batch/tasks/shared/LS_root/mounts/clusters/sweetdream/code/Users/labuser_44930_70189456/azureml/pipeline-logistic-titanic/titanic_service/titanic_scaler.pkl']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677384137806
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#scaler = pickle.load('titanic_service/titanic_scaler.pkl')\r\n",
        "with open('titanic_service/titanic_scaler.pkl','rb') as pickled:\r\n",
        "    oddone = pickle.load(pickled)\r\n",
        "\r\n",
        "oddone"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 70,
          "data": {
            "text/plain": "'titanic_scaler.pkl'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 70,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677385680910
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\r\n",
        "scaler = joblib.load('titanic_service/titanic_scaler.pkl')"
      ],
      "outputs": [],
      "execution_count": 67,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677385648000
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Invoke Endpoint\r\n",
        "import pickle\r\n",
        "import json\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "# Age, Sex, Fare\r\n",
        "x_new = [[22,0,7.25],[54,1,52]]\r\n",
        "#scaler = pickle.load(open('titanic_service/titanic_scaler.pkl', 'rb'))\r\n",
        "\r\n",
        "#scaler = pickle.load('titanic_service/titanic_scaler.pkl')\r\n",
        "scalar = pickle.load(open('../sandbox/scalar/scaler.pkl','rb'))\r\n",
        "#x_new = scalar.transform(np.array(x_new)[:,[0,2]]).tolist() # really made it hard for myself here...\r\n",
        "\r\n",
        "\r\n",
        "x_new= [[0.2711736617240512,0, 0.014151057562208049],\r\n",
        " [0.6732847449107816, 1,0.10149724044618187]]\r\n",
        "\r\n",
        "\r\n",
        "# Convert the array to a serializable list in a JSON document\r\n",
        "input_json = json.dumps({\"data\": x_new})\r\n",
        "\r\n",
        "# Call the web service, passing the input data (the web service will also accept the data in binary format)\r\n",
        "predictions = service.run(input_data = input_json)\r\n",
        "\r\n",
        "# Get the predicted class - it'll be the first (and only) one.\r\n",
        "predicted_classes = json.loads(predictions)\r\n",
        "\r\n",
        "for i in range(len(x_new)):\r\n",
        "    print (\"Passenger {}\".format(x_new[i]), predicted_classes[i] )\r\n",
        "     "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Passenger [0.2711736617240512, 0, 0.014151057562208049] Survived\nPassenger [0.6732847449107816, 1, 0.10149724044618187] Non-Survived\n"
        }
      ],
      "execution_count": 65,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677385477863
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#service.delete()\r\n",
        "print ('Service deleted.')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677384109945
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Research/References:\r\n",
        "\r\n",
        "- https://machinelearningmastery.com/how-to-save-and-load-models-and-data-preparation-in-scikit-learn-for-later-use/"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
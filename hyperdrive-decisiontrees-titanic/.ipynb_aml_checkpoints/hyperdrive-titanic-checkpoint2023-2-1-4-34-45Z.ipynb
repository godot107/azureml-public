{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#pip install azure-ai-ml\r\n"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677645213326
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\r\n",
        "\r\n",
        "from azureml.core import Dataset\r\n",
        "from azureml.data.datapath import DataPath\r\n",
        "#from azureml.core import train\r\n"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1677645213673
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\r\n",
        "from azureml.core import Workspace\r\n",
        "\r\n",
        "# Load the workspace from the saved config file\r\n",
        "ws = Workspace.from_config()\r\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ready to use Azure ML 1.49.0 to work with testerinos\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677645215448
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "default_ds = ws.get_default_datastore()\r\n",
        "\r\n",
        "if 'titanic dataset' not in ws.datasets:\r\n",
        "    Dataset.File.upload_directory(src_dir='data',\r\n",
        "                              target=DataPath(default_ds, 'titanic-data/')\r\n",
        "                              )\r\n",
        "\r\n",
        "    #Create a tabular dataset from the path on the datastore (this may take a short while)\r\n",
        "    tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'titanic-data/titanic.csv'))\r\n",
        "\r\n",
        "    # Register the tabular dataset\r\n",
        "    try:\r\n",
        "        tab_data_set = tab_data_set.register(workspace=ws, \r\n",
        "                                name='titanic dataset',\r\n",
        "                                description='titanic data',\r\n",
        "                                tags = {'format':'CSV'},\r\n",
        "                                create_new_version=True)\r\n",
        "        print('Dataset registered.')\r\n",
        "    except Exception as ex:\r\n",
        "        print(ex)\r\n",
        "else:\r\n",
        "    print('Dataset already registered.')"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677645216705
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "\r\n",
        "experiment_folder = 'titanic_training-hyperdrive'\r\n",
        "os.makedirs(experiment_folder, exist_ok=True)\r\n",
        "\r\n",
        "print('Folder ready.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Folder ready.\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677645216899
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/titanic_training.py\r\n",
        "# Import libraries\r\n",
        "import argparse, joblib, os\r\n",
        "from azureml.core import Run\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.ensemble import GradientBoostingClassifier\r\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\r\n",
        "\r\n",
        "# Get the experiment run context\r\n",
        "run = Run.get_context()\r\n",
        "\r\n",
        "# Get script arguments\r\n",
        "parser = argparse.ArgumentParser()\r\n",
        "\r\n",
        "# Input dataset\r\n",
        "parser.add_argument(\"--input-data\", type=str, dest='input_data', help='training dataset')\r\n",
        "\r\n",
        "# Hyperparameters\r\n",
        "parser.add_argument('--learning_rate', type=float, dest='learning_rate', default=0.1, help='learning rate')\r\n",
        "parser.add_argument('--n_estimators', type=int, dest='n_estimators', default=100, help='number of estimators')\r\n",
        "\r\n",
        "# Add arguments to args collection\r\n",
        "args = parser.parse_args()\r\n",
        "\r\n",
        "# Log Hyperparameter values\r\n",
        "run.log('learning_rate',  np.float(args.learning_rate))\r\n",
        "run.log('n_estimators',  np.int(args.n_estimators))\r\n",
        "\r\n",
        "# load the diabetes dataset\r\n",
        "print(\"Loading Data...\")\r\n",
        "diabetes = run.input_datasets['training_data'].to_pandas_dataframe() # Get the training data from the estimator input\r\n",
        "\r\n",
        "# Separate features and labels\r\n",
        "X, y = diabetes[['Age','Sex','Fare']].values, diabetes['Survived'].values\r\n",
        "\r\n",
        "# Split data into training set and test set\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\r\n",
        "\r\n",
        "# Train a Gradient Boosting classification model with the specified hyperparameters\r\n",
        "print('Training a classification model')\r\n",
        "model = GradientBoostingClassifier(learning_rate=args.learning_rate,\r\n",
        "                                   n_estimators=args.n_estimators).fit(X_train, y_train)\r\n",
        "\r\n",
        "# calculate accuracy\r\n",
        "y_hat = model.predict(X_test)\r\n",
        "acc = np.average(y_hat == y_test)\r\n",
        "print('Accuracy:', acc)\r\n",
        "run.log('Accuracy', np.float(acc))\r\n",
        "\r\n",
        "# calculate AUC\r\n",
        "y_scores = model.predict_proba(X_test)\r\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\r\n",
        "print('AUC: ' + str(auc))\r\n",
        "run.log('AUC', np.float(auc))\r\n",
        "\r\n",
        "# Save the model in the run outputs\r\n",
        "os.makedirs('outputs', exist_ok=True)\r\n",
        "joblib.dump(value=model, filename='outputs/titanic_model.pkl')\r\n",
        "\r\n",
        "run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting titanic_training-hyperdrive/titanic_training.py\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "\r\n",
        "cluster_name = \"sweetcluster\"\r\n",
        "\r\n",
        "try:\r\n",
        "    # Check for existing compute target\r\n",
        "    training_cluster = ComputeTarget(workspace=ws, name=cluster_name)\r\n",
        "    print('Found existing cluster, use it.')\r\n",
        "except ComputeTargetException:\r\n",
        "    # If it doesn't already exist, create it\r\n",
        "    try:\r\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\r\n",
        "        training_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\r\n",
        "        training_cluster.wait_for_completion(show_output=True)\r\n",
        "    except Exception as ex:\r\n",
        "        print(ex)\r\n",
        "    "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing cluster, use it.\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677645217257
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "%%writefile $experiment_folder/hyperdrive_env.yml\r\n",
        "name: batch_environment\r\n",
        "dependencies:\r\n",
        "- python=3.6.2\r\n",
        "- scikit-learn\r\n",
        "- pandas\r\n",
        "- numpy\r\n",
        "- pip\r\n",
        "- pip:\r\n",
        "  - azureml-defaults"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting titanic_training-hyperdrive/hyperdrive_env.yml\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment, ScriptRunConfig, Environment\r\n",
        "from azureml.train.hyperdrive import GridParameterSampling, HyperDriveConfig, PrimaryMetricGoal, choice\r\n",
        "from azureml.widgets import RunDetails\r\n",
        "\r\n",
        "# Create a Python environment for the experiment\r\n",
        "hyper_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/hyperdrive_env.yml\")\r\n",
        "\r\n",
        "# Get the training dataset\r\n",
        "titanic_ds = ws.datasets.get(\"titanic dataset\")\r\n",
        "\r\n",
        "# Create a script config\r\n",
        "script_config = ScriptRunConfig(source_directory=experiment_folder,\r\n",
        "                                script='titanic_training.py',\r\n",
        "                                # Add non-hyperparameter arguments -in this case, the training dataset\r\n",
        "                                arguments = ['--input-data', titanic_ds.as_named_input('training_data')],\r\n",
        "                                environment=hyper_env,\r\n",
        "                                compute_target = training_cluster)\r\n",
        "\r\n",
        "# Sample a range of parameter values\r\n",
        "params = GridParameterSampling(\r\n",
        "    {\r\n",
        "        # Hyperdrive will try 6 combinations, adding these as script arguments\r\n",
        "        '--learning_rate': choice(0.01, 0.1, 1.0),\r\n",
        "        '--n_estimators' : choice(10, 100)\r\n",
        "    }\r\n",
        ")\r\n",
        "\r\n",
        "# Configure hyperdrive settings\r\n",
        "hyperdrive = HyperDriveConfig(run_config=script_config, \r\n",
        "                          hyperparameter_sampling=params, \r\n",
        "                          policy=None, # No early stopping policy\r\n",
        "                          primary_metric_name='AUC', # Find the highest AUC metric\r\n",
        "                          primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \r\n",
        "                          max_total_runs=6, # Restict the experiment to 6 iterations\r\n",
        "                          max_concurrent_runs=2) # Run up to 2 iterations in parallel\r\n",
        "\r\n",
        "# Run the experiment\r\n",
        "experiment = Experiment(workspace=ws, name='mslearn-titanic-hyperdrive')\r\n",
        "run = experiment.submit(config=hyperdrive)\r\n",
        "\r\n",
        "# Show the status in the notebook as the experiment runs\r\n",
        "RunDetails(run).show()\r\n",
        "run.wait_for_completion()"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677645217618
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "# Print all child runs, sorted by the primary metric\r\n",
        "for child_run in run.get_children_sorted_by_primary_metric():\r\n",
        "    print(child_run)\r\n",
        "\r\n",
        "# Get the best run, and its metrics and arguments\r\n",
        "best_run = run.get_best_run_by_primary_metric()\r\n",
        "best_run_metrics = best_run.get_metrics()\r\n",
        "script_arguments = best_run.get_details() ['runDefinition']['arguments']\r\n",
        "print('Best Run Id: ', best_run.id)\r\n",
        "print(' -AUC:', best_run_metrics['AUC'])\r\n",
        "print(' -Accuracy:', best_run_metrics['Accuracy'])\r\n",
        "print(' -Arguments:',script_arguments)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677645217743
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Model\r\n",
        "\r\n",
        "# Register model\r\n",
        "best_run.register_model(model_path='outputs/titanic_model.pkl', model_name='titanic_model',\r\n",
        "                        tags={'Training context':'Hyperdrive'},\r\n",
        "                        properties={'AUC': best_run_metrics['AUC'], 'Accuracy': best_run_metrics['Accuracy']})\r\n",
        "\r\n",
        "# List registered models\r\n",
        "for model in Model.list(ws):\r\n",
        "    print(model.name, 'version:', model.version)\r\n",
        "    for tag_name in model.tags:\r\n",
        "        tag = model.tags[tag_name]\r\n",
        "        print ('\\t',tag_name, ':', tag)\r\n",
        "    for prop_name in model.properties:\r\n",
        "        prop = model.properties[prop_name]\r\n",
        "        print ('\\t',prop_name, ':', prop)\r\n",
        "    print('\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677645217765
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
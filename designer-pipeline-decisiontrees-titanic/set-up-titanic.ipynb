{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\r\n",
        "\r\n",
        "import azureml.core\r\n",
        "from azureml.core import Workspace\r\n",
        "\r\n",
        "from azureml.core import Dataset\r\n",
        "from azureml.data.datapath import DataPath\r\n",
        "\r\n",
        "import os"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1677528988722
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the workspace from the saved config file\r\n",
        "ws = Workspace.from_config()\r\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ready to use Azure ML 1.48.0 to work with testerinos\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677528992634
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "default_ds = ws.get_default_datastore()\r\n",
        "\r\n",
        "if 'titanic dataset' not in ws.datasets:\r\n",
        "    Dataset.File.upload_directory(src_dir='data',\r\n",
        "                              target=DataPath(default_ds, 'titanic-data/')\r\n",
        "                              )\r\n",
        "\r\n",
        "    #Create a tabular dataset from the path on the datastore (this may take a short while)\r\n",
        "    tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'titanic-data/titanic.csv'))\r\n",
        "\r\n",
        "    # Register the tabular dataset\r\n",
        "    try:\r\n",
        "        tab_data_set = tab_data_set.register(workspace=ws, \r\n",
        "                                name='titanic dataset',\r\n",
        "                                description='titanic data',\r\n",
        "                                tags = {'format':'CSV'},\r\n",
        "                                create_new_version=True)\r\n",
        "        print('Dataset registered.')\r\n",
        "    except Exception as ex:\r\n",
        "        print(ex)\r\n",
        "else:\r\n",
        "    print('Dataset already registered.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2023-02-27 20:16:39.057223 | ActivityCompleted: Activity=get_by_name, HowEnded=Failure, Duration=106.62 [ms], Info = {'activity_id': '948a9ce7-c290-4e46-8659-0155f681ccf2', 'activity_name': 'get_by_name', 'activity_type': 'PublicApi', 'app_name': 'dataset', 'source': 'azureml.dataset', 'version': '1.48.0', 'dataprepVersion': '4.8.4', 'sparkVersion': '', 'subscription': '', 'run_id': '', 'resource_group': '', 'workspace_name': '', 'experiment_id': '', 'location': '', 'completionStatus': 'Success', 'durationMs': 0.11}, Exception=UserErrorException; UserErrorException:\n\tMessage: Cannot find dataset registered with name \"titanic dataset\" (version: None) in the workspace.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Cannot find dataset registered with name \\\"titanic dataset\\\" (version: None) in the workspace.\"\n    }\n}\nFailed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\nFailed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Validating arguments.\nArguments validated.\nUploading file to titanic-data/\nUploading an estimated of 3 files\nUploading data/.amlignore\nUploaded data/.amlignore, 1 files out of an estimated total of 3\nUploading data/.amlignore.amltmp\nUploaded data/.amlignore.amltmp, 2 files out of an estimated total of 3\nUploading data/titanic.csv\nUploaded data/titanic.csv, 3 files out of an estimated total of 3\nUploaded 3 files\nCreating new dataset\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677529013013
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Provision Compute Cluster for Pipeline"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "\r\n",
        "cluster_name = \"sweetdreams\"\r\n",
        "\r\n",
        "try:\r\n",
        "    # Check for existing compute target\r\n",
        "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\r\n",
        "    print('Found existing cluster, use it.')\r\n",
        "except ComputeTargetException:\r\n",
        "    # If it doesn't already exist, create it\r\n",
        "    try:\r\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\r\n",
        "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\r\n",
        "        pipeline_cluster.wait_for_completion(show_output=True)\r\n",
        "    except Exception as ex:\r\n",
        "        print(ex)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing cluster, use it.\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677529260066
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}